---
title: "Wrangling-B"
tutorial:
  id: "02-wrangling-B"
output:
  learnr::tutorial:
      progressive: true
      allow_skip: true
runtime: shiny_prerendered
description: "Chapter 2 Tutorial -- Part B"
---

<!-- Things to fix in this tutorial. -->

<!-- Each group (at least for things like characters and factors) should be introduced with a few sentences, ideally with references to the appropriate section of the book. -->

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(stringr)
library(learnr)
library(skimr)
library(shiny)
library(PPBDS.data)
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
options(tutorial.exercise.timelimit = 60, tutorial.storage="local") 

# Needed for later sections of the tutorial 

library(fivethirtyeight)
library(nycflights13)
library(ggthemes)
```

## Confirm Correct Package Version
###

Confirm that you have the correct version of PPBDS.data installed by pressing "Run Code."

```{r confirm, exercise=TRUE}
packageVersion('PPBDS.data')
```

The answer should be ‘0.3.2.9004’, or a higher number. If it is not, you should upgrade your installation by issuing these commands:


```{r confirm-advice, echo=TRUE, eval=FALSE}
remove.packages('PPBDS.data')  
library(remotes)  
remotes::install_github('davidkane9/PPBDS.data')  
```

Strictly speaking, it should not be necessary to remove a package. Just installing it again should overwrite the current version. But weird things sometimes happen, so removing first is the safest approach. 

## Name 
###

``` {r name, echo=FALSE}
question_text(
  "Student Name:",
  answer(NULL, correct = TRUE),
  incorrect = "Ok",
  try_again_button = "Modify your answer",
  allow_retry = TRUE
)
```

## Email
###

``` {r email, echo=FALSE}
question_text(
  "Email:",
  answer(NULL, correct = TRUE),
  incorrect = "Ok",
  try_again_button = "Modify your answer",
  allow_retry = TRUE
)
```

## Introduction
###

Purpose of this tutorial is to provide several full scale exercises, each using with a real data set --- one which requires some cleaning and organizing --- and finishing with a professional quality plot. We start each group by showing you the plot which we will replicate by the end.


## National Health and Nutrition Survey
###

`nhanes` is a data set included in the **PPBDS.data** package. It includes data from the "National Health and Nutrition Examination Survey," which contains the personal and physical information of 10,000 Americans from two surveys in 2009 and 2011. The goal of this series of exercises is to build, line-by-line, the code needed to recreate this plot.

```{r}
nhanes_plot <- nhanes %>%
  mutate(weight = weight * 2.2, height = height / 30.48) %>%
  select(gender, weight, height, bmi) %>%
  drop_na(weight, height) %>% 
  ggplot(mapping = aes(x = weight, y = height, color = bmi)) +
    geom_jitter() +
    geom_smooth(se = FALSE, color = "dodgerblue") +
    facet_wrap(~ gender) + 
    theme_clean() + 
    labs(y = "Height (feet)",
         x = "Weight (pounds)",
         title = "Height Versus Weight in the US",
         subtitle = "Relation between weight and height more positive for heavy men",
         caption = "Source: NHANES")

nhanes_plot
```


### Exercise 1

Begin by running `summary()` on `nhanes`. Based on the results, try to guess what the units of measurement are for the `weight` and `height` variables.

```{r nhanes1, exercise = TRUE}

```

### Exercise 2

In the original tibble, `weight` is measured in kg and `height` in cm. Using `mutate()`, multiply `weight` by 2.2 and divide `height` by 30.48 to convert units into pounds and feet. 

```{r nhanes2, exercise = TRUE}

```

```{r nhanes2-hint, eval = FALSE}
nhanes %>%
  mutate(weight = ..., height = ...)
```

### Exercise 3

`select()` the `gender`, `weight`, `height`, and `bmi` columns. 

```{r nhanes3, exercise = TRUE}

```

```{r nhanes3-hint, eval=FALSE}
... %>%
  select(..., ..., ..., ...)
```

### Exercise 4

Use tidyr's `drop_na()` to remove all rows with a value of `NA` in either the `weight` or `height` columns.


```{r nhanes4, exercise = TRUE, exercise.lines = 4}

```

```{r nhanes4-hint, eval = FALSE}
... %>%
  drop_na(..., ...)
```

### Exercise 5

Call `ggplot()` to make a jittered scatterplot that maps `weight` to the x-axis, `height` to the y-axis, and `bmi` to the color aesthetic. 

```{r nhanes5, exercise = TRUE}

```


```{r nhanes5-hint-1, eval = FALSE}
# Use geom_jitter().
```

```{r nhanes5-hint-2, eval=FALSE}
... %>% 
  gplot(data = ..., aes(x = ..., y = ..., color = ...))
```

### Exercise 6

Add a trend line layer to your plot with `geom_smooth()`. Set the `se` argument of `geom_smooth()` to FALSE in order to remove the confidence interval, and change the `color` of the line to "dodgerblue." 


```{r nhanes6, exercise = TRUE}

```


```{r nhanes6-hint-1, eval = FALSE}
# The se argument should be equal to FALSE.
```

```{r nhanes6-hint-2, eval=FALSE}
... + 
  geom_smooth(se = ..., color = ...)
```

### Exercise 7

Use `facet_wrap()` to facet the graph by `gender`.


```{r nhanes7, exercise = TRUE}

```

```{r nhanes7-hint, eval=FALSE}
... +
  facet_wrap(...)
```


### Exercise 8

Finally, adjust the feel of the graph with `theme_clean()` from the **ggthemes** package. 



```{r nhanes8, exercise = TRUE}

```


### Exercise 9

Great work! From this graph, we can see that children of both genders tend to grow very quickly without gaining much weight (this is the very steep slope at the beginning of the two graphs). However, after people reach between 100-120 pounds, weight gain becomes coupled with a substantially smaller increase in height. Additionally, both weight and height seem to be higher for males than for females on average. Finally, we can infer from looking at the color gradient that a high `bmi` (i.e. brighter colors) corresponds with higher weight and lower height.

To finish your plot, use `labs()` to give the graph a title and subtitle of your choice. Here, again, is our version.

```{r nhanes9-answer}
nhanes_plot
```

```{r nhanes9, exercise = TRUE}

```



## Kenya Voting
###

The `kenya` data set from the **PPBDS.data** package records the data from a study in which poll stations in Kenya were assigned to either the control group or a group in which one or more methods --- an SMS reminder, canvassing, etc. --- were used to encourage voter registration. We will recreate this plot:


```{r kenya-answer}
kenya_plot <- kenya %>%
  filter(treatment %in% c("control", "local", 
                          "SMS", "canvass")) %>%
  droplevels() %>%
  select(treatment, mean_age, reg_byrv13) %>%
  drop_na(mean_age) %>%
  mutate(age_half = ntile(mean_age, 2)) %>%
  group_by(treatment, age_half) %>%
  summarize(mean_turnout = mean(reg_byrv13, na.rm = TRUE)) %>% 
  ggplot(mapping = aes(x = fct_reorder(treatment, mean_turnout), 
                       y = mean_turnout)) +
    geom_col() +
    theme_bw() +
    labs(title = "Turnout Changes in a Kenyan Election",
         subtitle = "Local canvassing has the largest effect",
         x = "Treatment",
         y = "Change in Mean Turnout")

kenya_plot
```


### Exercise 1

Start by `glimpse()`'ing the `kenya` data set.


```{r kenya1, exercise = TRUE}

```

```{r kenya1-hint, eval = FALSE}
glimpse(kenya)
```

### Exercise 2

Pipe `kenya` into the `count()` function to count the number of poll stations in each `treatment` group.


```{r kenya2, exercise = TRUE}

```

```{r kenya2-hint, eval = FALSE}
kenya %>%
  count(...)
```

### Exercise 3

Using a pipe and the `%in%` operator, `filter()` `kenya` to only the rows with a `treatment` of "control," "local," "SMS," or "canvass." 


```{r kenya3, exercise = TRUE}

```

```{r kenya3-hint-1, eval=FALSE}
kenya %>%
  filter(treatment %in% ...)
```

```{r kenya3-hint-2, eval=FALSE}
kenya %>%
  filter(treatment %in% c(...))
```

### Exercise 4

Because `treatment` is a factor, call `droplevels()` immediately after the `filter()` call to avoid future complications. 


```{r kenya4, exercise = TRUE}

```

### Exercise 5 

`select()` the `treatment`, `mean_age`, and `reg_byrv13` columns. 


```{r kenya5, exercise = TRUE}

```


### Exercise 6

Use tidyr's `drop_na()` to remove all rows with a value of `NA` in the `mean_age` column.

```{r kenya6, exercise = TRUE}

```

```{r kenya6-hint, eval = FALSE}
kenya %>%
  filter(treatment %in% c("control", "local", "SMS", "canvass")) %>%
  droplevels() %>%
  select(treatment, mean_age, reg_byrv13)
  drop_na(...)
```

### Exercise 7

The dplyr `ntile()` function divides a continuous numerical value into categories depending on its size. Try running the following code to see how we can categorize the polling stations into 4 equally-sized groups based on the `distance` to the polling station.


```{r kenya7, exercise = TRUE}
kenya %>%
  mutate(distance_quartile = ntile(distance, 4))
```

### Exercise 8 

Use `mutate()` and `ntile()` to create the variable `age_half`, which categorizes the `mean_age` variable into 2 groups: the younger half, and the older half. Add this to the end of our full pipe.


```{r kenya8, exercise = TRUE}

```

```{r kenya8-hint, eval = FALSE}
# ntile(mean_age, 2) will categorize age into the younger half and the older
# half.

```

### Exercise 9

Group the data by `treatment` and `age_half`.


```{r kenya9, exercise = TRUE}

```

```{r kenya9-hint, eval=FALSE}
... %>%
  group_by(...)
```

### Exercise 10

Using `summarize()`, calculate the variable `mean_turnout` as the average value of `reg_byrv13` in each group. Remember to set the `na.rm` argument of `mean()` to `TRUE`, as there are some `NA` values in the `reg_byrv13` column.


```{r kenya10, exercise = TRUE}

```

```{r kenya10-hint, eval=FALSE}
# Don't forget the .groups argument to summarize(). Never ignore warning
# messages.
```

### Exercise 11 

Use `ggplot()` at the end of the pipe to make a bar graph with `treatment` on the x-axis and `mean_turnout` on the y-axis.

```{r kenya11, exercise = TRUE}

```


```{r kenya11-hint-2, eval=FALSE}
# Remember to use geom_col() instead of geom_bar() when you map something to the
# y-axis.
```

### Exercise 12 

Already, we can see that one of the treatments is significantly more effective at increasing turnout than others. Continue by using `facet_wrap()` to facet the data by `age_half`. 


```{r kenya12, exercise = TRUE}

```

<!-- DK: Get rid of facet_wrap, or anything else which does not make the final graph. -->


### Exercise 13

To make the graph easier to read, use `fct_reorder()` to reorder the `treatment` variable by `mean_turnout`. Note, you will no longer use the `facet_wrap()`, as this will cause issues with the ordering of the `treatment` categories.


```{r kenya13, exercise = TRUE}

```

```{r kenya13-hint, eval = FALSE}
...  %>% 
  ggplot(mapping = aes(x = fct_reorder(..., ...), y = ...)) +
    geom_col()
```

### Exercise 14

Improve the aesthetics of the graph by changing the theme to `theme_bw()`.

```{r kenya14, exercise = TRUE}

```

### Exercise 15

Great job! This graph allows us to see that the presence of a local administrator at the polling location is by far the most effective strategy for increasing voter turnout. In addition, older voters (category 2) are not only more likely to vote than younger voters, but they are also influenced to a greater extent by the presence of a local administrator.

To finish your plot, use `labs()` to change the x-axis label to "Treatment." In addition, give the graph a title, subtitle and y-axis label of your choosing. Your plot should look something like this:

```{r kenya15-answer}
kenya_plot
```

```{r kenya15, exercise = TRUE}

```



## Seguro Popular
###

The `sps` data set from the **PPBDS.data** package contains information about a study done on a popular Mexican health insurance program, Seguro Popular. In the study, some Mexican health clusters were randomly "treated." The treatment consisted of encouragement for people in that health cluster to enroll in the health insurance program, as well as funds to improve health facilities in that cluster. We will create this plot:

```{r sps_plot}
sps_plot <- sps %>%
  filter(education %in% c("preschool", "secondary", 
                          "high school", "college")) %>%
  select(-c(health_exp_1m, t2_health_exp_1m)) %>%
  mutate(change_in_expenses = t2_health_exp_3m - health_exp_3m) %>%
  group_by(treatment, education) %>%
  summarize(mean_change_in_expenses = mean(change_in_expenses)) %>%
  mutate(treatment = as.factor(treatment)) %>% 
  ggplot(mapping = aes(x = fct_reorder(education, mean_change_in_expenses), 
                       y = mean_change_in_expenses, fill = treatment)) +
    geom_col(position = position_dodge(preserve = "single")) + 
    scale_fill_brewer(palette = "Paired", labels = c("No", "Yes")) +
    theme_minimal() +
    labs(x = "Education",
         y = "Average Change in Expenses",
         title = "Spending Changes and Seguro Popular",
         subtitle = "Honestly, not sure what is going on here . . .",
         caption = "Source: King et al. (2009)")

sps_plot
```



### Exercise 1 

Start by calling `glimpse()` on `sps`.


```{r sps1, exercise = TRUE}

```

```{r sps1-hint, eval=FALSE}
glimpse(...)
```

### Exercise 2

Using a pipe and the `%in%` operator, `filter()` `sps` to the observations with an `education` of "preschool," "secondary," "high school," or "college." 


```{r sps2, exercise = TRUE}

```

```{r sps2-hint-1, eval=FALSE}
sps %>%
  filter(education %in% ...)
```

```{r sps2-hint-2, eval=FALSE}
sps %>% 
  filter(education %in% c(...))
```

### Exercise 3

Use `select()` to remove the columns `health_exp_1m` and `t2_health_exp_1m` (these measure health expenses over the past month, whereas `health_exp_3m` and `t2_health_exp_3m` measure health expenses over the past 3 months). 


```{r sps3, exercise = TRUE}

```

```{r sps3-hint-1, eval=FALSE}
# Remember that select(-column_name) returns all columns except for that column.
```

```{r sps3-hint-2, eval=FALSE}
# Consider using c()
```


### Exercise 4 

Use `mutate()` to create a new variable, `change_in_expenses`, equal to `health_exp_3m` subtracted from `t2_health_exp_3m` (this measures the change in expenses after the treatment period). 


```{r sps4, exercise = TRUE}

```

### Exercise 5

Group the data by `treatment` and `education`.



```{r sps5, exercise = TRUE}

```

```{r sps5-hint, eval=FALSE}
# Use the group_by() function.
```

### Exercise 6

Using `summarize()`, calculate `mean_change_in_expenses`, the average of the `change_in_expenses` for each group.


```{r sps6, exercise = TRUE}
  
```

```{r sps6-hint, eval = FALSE}
# Use the summarize() function and the helper function mean(). Your pipe should
# look like:

sps %>%
  filter(education %in% c("preschool", "secondary", "high school", "college")) %>%
  select(-c(health_exp_1m, t2_health_exp_1m)) %>%
  mutate(change_in_expenses = t2_health_exp_3m - health_exp_3m) %>%
  group_by(treatment, education) %>%
  summarize(mean_change_in_expenses = mean(change_in_expenses))
```

### Exercise 7

use `ggplot()` to make a bar graph that maps `education` to the x-axis, `mean_change_in_expenses` to the y-axis, and `treatment` to the fill aesthetic.


```{r sps7, exercise = TRUE}

```

```{r sps7-hint, eval=FALSE}
# Remember to use geom_col() instead of geom_bar() when mapping a variable to
# the y-axis.
```

### Exercise 8 

Use the `position_dodge` function with `preserve` equal to "single" to create a dodged barplot. It does not work well! Don't worry, we will fix in in the next exercise.


```{r sps8, exercise = TRUE}

```

```{r sps8-hint,eval=FALSE}
# You can use the position argument in the geom_col() layer
```

### Exercise 9

Because `treatment` column is an integer and not a factor, we can't group our data by it. To fix this problem, use `mutate()` and `as.factor()` to change `treatment` to a factor. 

```{r sps9, exercise = TRUE}

```


### Exercise 10

Use `fct_reorder()` to reorder the four educations by `mean_change_in_expenses`.


```{r sps10, exercise = TRUE}

```


### Exercise 11

Change the aesthetics of the plot by using `scale_fill_brewer()` with the "Paired" palette. In addition, adjust the `labels` argument of `scale_fill_brewer()` so that the legend's labels are equal to the vector ("No", "Yes").

```{r sps11, exercise = TRUE}

```

```{r sps11-hint, eval=FALSE}
...  + 
    scale_fill_brewer(palette = ..., labels = ...)
```

### Exercise 12

Add `theme_minimal()` to change the style of the graph.


```{r sps12, exercise = TRUE}

```

### Exercise 13

Great work! The first thing to notice from our graph is that all of the bars are positive, implying that all medical costs (regardless of treatment) went up over time. However, it is also clear that the treatment caused costs to rise less for all education groups. Finally, it is worth noting that the education category `preschool` is the only category that the treatment did not significantly affect costs. Since the treatment was designed to help less educated people the most, this is definitely a fact worth investigating.

To finish your plot, use `labs()` to change the x-axis label to "education." Also, give the graph a title and subtitle of your choice. Here, again, is our version:


```{r sps13-answer}
sps_plot
```

```{r sps13, exercise = TRUE}

```

## Shaming 
###

The `shaming` data set chronicles a study that attempted to measure the impact of social pressure on voting. Nearly 350,000 people in Michigan were randomly assigned to 1 of 5 treatment groups before the 2006 Michigan primary. All 5 groups were sent mail before the primary: the "Civic Duty" group had an extra reminder that voting was a civic responsibility, the "Hawthorne" group was told that whether or not they voted would be in the public record, the "Self" group was actually *sent* the public record of whether or not they voted in 2004, and the "Neighbors" group was sent both their voting record and their neighbors' voting record from 2004. We will reproduce this plot.

```{r sh_goal}
shaming_plot <- shaming %>%
  select(primary_04, primary_06, treatment) %>%
  mutate(primary_04 = if_else(condition = 
                                str_detect(primary_04, "Yes"),
                                true = 1L,
                                false = 0L)) %>%
  pivot_longer(cols = c(primary_04, primary_06), 
               names_to = "year", values_to = "voted") %>%
  group_by(treatment, year, voted) %>%
  summarize(num_voters = n(), .groups = "drop") %>%
  mutate(voted = if_else(condition = voted == 1,
                         true = "did_vote",
                         false = "did_not_vote")) %>%
  pivot_wider(names_from = voted, values_from = num_voters)  %>%
  mutate(pct_voted = did_vote / (did_vote + did_not_vote)) %>% 
  ggplot(mapping = aes(x = fct_reorder(treatment, pct_voted), 
                       y = pct_voted, fill = year)) +
    geom_col(position = position_dodge(preserve = "single")) +
    coord_cartesian(ylim = c(0.2, 0.45)) +
    labs(x = "Treatment",
         y = "Voting Percentage",
         title = "Voting Rates Based on Mailings",
         subtitle = "Shaming people makes them more likely to vote",
         caption = "Source: Gerber, Green, and Larimer (2008).") +
    theme_fivethirtyeight()

shaming_plot
```

### Exercise 1

Start by running `skim()` on `shaming`. See if you can find out how many of the participants voted in `general_04`. Also, pay close attention to the data types of each of the variables.

```{r shaming1, exercise = TRUE}

```

### Exercise 2

Make the data set easier to visualize by limiting the columns to `treatment`, `primary_04`, and `primary_06`. 

```{r shaming2, exercise = TRUE}

```

```{r shaming2-hint, eval=FALSE}
# Use the select() function.
```

### Exercise 3

Use `pivot_longer()` to map the *names* of the `primary_04` and `primary_06` columns to a new column, "year," and the *values* of those two columns to a new column, "voted." What goes wrong?


```{r shaming3, exercise = TRUE}

```

```{r shaming3-hint, eval = FALSE}
...  %>%
  pivot_longer(cols = ..., names_to = ..., values_to = ...)
```

### Exercise 4

`pivot_longer()` won't let us combine one column of `<chr>` data with one column of `<int>` data. Therefore, we're going to have to change the data type of one of the columns.

Before we do that, though, we need to understand the dplyr `if_else()` function. `if_else()` is used alongside `mutate()` to create 2 different values depending on whether a `condition` is `TRUE` or `FALSE`. `if_else()` is a more modern, and somewhat safer, version of `ifelse()`.

Run the following code to see how we can categorize the `birth_year` column into 2 groups based on whether the person was born before 1950.

```{r shaming4, exercise = TRUE, exercise.lines = 6}
shaming %>%
  select(birth_year) %>%
  mutate(born_before_1950 = if_else(condition = birth_year < 1950,
                                 true = "yes",
                                 false = "no"))
```

### Exercise 5

Now, use `if_else()` before the `pivot_longer()` statement to `mutate()` the `primary_04` column. The condition should should be a `str_detect()` of the string "Yes" in `primary_04`. If the condition is true, return 1 **as an integer**, and if the condition is false, return 0 **as an integer**. Don't forget to `pivot_longer()` once again. 


```{r shaming5, exercise = TRUE, eval = FALSE, exercise.lines = 5}

```

```{r shaming5-hint-1, eval=FALSE}
# Remember to append the letter "L" to make something an integer; e.g. 22L.
```

```{r shaming5-hint-2, eval=FALSE}
# The condition of the if_else() should be str_detect(primary_04, "Yes").
```

### Exercise 6

Great job! To continue, group the data by `treatment`, `year`, and `voted`.


```{r shaming6, exercise = TRUE}

```

```{r shaming6-hint, eval=FALSE}
# Use the group_by() function.
```

### Exercise 7

Using `summarize()`, create the variable `num_voters` that simply counts the number of rows in each group.

```{r shaming7, exercise = TRUE}

```

```{r shaming7-hint, eval=FALSE}
# Remember that n() counts the number of rows in each group.
```

### Exercise 8

The `voted` column is a bit difficult to understand, as a numerical value (0 or 1) is used to represent an idea (the person did or did not vote). Use another `if_else()` statement to `mutate()` the `voted` column. Condition your `if_else()` on whether `voted` is equal to 1: true should return "did_vote," and false should return "did_not_vote."


```{r shaming8, exercise = TRUE}

```

```{r shaming8-hint-1, eval=FALSE}
# The condition of the if_else() should be voted == 1.
```

```{r shaming8-hint-2, eval=FALSE}
# Your pipe should look something like this:

shaming %>%
  select(primary_04, primary_06, treatment) %>%
  mutate(primary_04 = if_else(condition = 
                                str_detect(primary_04, "Yes"),
                                true = 1L,
                                false = 0L)) %>%
  pivot_longer(cols = c(primary_04, primary_06), 
               names_to = "year", values_to = "voted") %>%
  group_by(treatment, year, voted) %>%
  summarize(num_voters = n(), .groups = "drop") %>%
  mutate(voted = if_else(condition = voted == 1,
                         true = "did_vote",
                         false = "did_not_vote"))
```

### Exercise 9

Now, we want `did_vote` and `did_not_vote` to be their own columns. Call a `pivot_wider()` function that gets its column names from `voted` and its values from `num_voters`.


```{r shaming9, exercise = TRUE}

```

```{r shaming9-hint, eval = FALSE}
...  %>%
  pivot_wider(names_from = ..., values_from = ...)
```

### Exercise 10

`mutate()` a new variable, `pct_voted`, equal to the number of people who `did_vote` divided by the total number of people.

```{r shaming10, exercise = TRUE}

```

```{r shaming10-hint, eval=FALSE}
# Note that the total number of people is equal to (did_vote + did_not_vote).
```

### Exercise 11

Call `ggplot()` to make a bar chart that maps `treatment` to the x-axis, `pct_voted` to the y-axis, and `year` to the fill aesthetic. 


```{r shaming11, exercise = TRUE, exercise.lines = 14}

```

```{r shaming11-hint, eval=FALSE}
# Remember to use geom_col() instead of geom_bar() when you map something to the
# y-axis.
```

### Exercise 12

A stacked barplot is very hard to analyze here. Use the `position_dodge()` function with `preserve` set to "single" to make the graph a dodged barplot.



```{r shaming12, exercise = TRUE}

```

```{r shaming12-hint, eval = FALSE}
# Set the position argument of geom_col()
```

### Exercise 13

Use `fct_reorder()` to reorder the five different `treatment`s by `pct_voted`. In other words, you need to change the value of `x`, probably using `fct_reorder()`, within the call to `aes()`.

```{r shaming13, exercise = TRUE}

```

### Exercise 14

Finally, use the `coord_cartesian` function to adjust the graph's zoom by setting `ylim` to the vector `(0.2, 0.45)`.


```{r shaming14, exercise = TRUE}

```

### Exercise 15

From this graph, the first thing to notice is that all five of the treatment categories had approximately the same average voter turnout in 2004. We can also see that turnout decreased across the board in 2006. However, each additional level of social shaming led to a substantial increase in voter turnout, with the "Neighbors" treatment particularly effective.

Clean up your graph with some sensible labels. Again, here is our version.

```{r shaming15-answer}
shaming_plot
```

```{r shaming15, exercise = TRUE}

```

<!-- ## Q-Guide -->
<!-- ### -->


<!-- The `qscores` data set from the **PPBDS.data** package includes information about 748 courses at Harvard during the 2018-2019 school year, including their department, student enrollment, average time spent on homework, and the average student rating of the course. -->

<!-- ### Exercise 1  -->

<!-- Start by piping `qscores` into `sample_n()` to view 5 random rows in the data set. -->

<!-- ```{r qscores1, exercise = TRUE} -->

<!-- ``` -->

<!-- ### Exercise 2 -->

<!-- Our goal will be to analyze the homework patterns of Harvard classes by department. To start, use a pipe to `select()` the `department` and `hours` columns -- `hours` represents the average workload of a class per week in hours, based on student surveys.  -->

<!-- ```{r qscores2, exercise = TRUE} -->

<!-- ``` -->

<!-- ### Exercise 3 -->

<!-- Next, group the data by `department`. -->


<!-- ```{r qscores3, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r qscores3-hint} -->
<!-- # Use the group_by() function. -->
<!-- ``` -->

<!-- ### Exercise 4 -->

<!-- Use `summarize()` to create 3 new variables: `num_classes` equal to the number of rows (i.e. classes) in each `department` group, `mean_hours` equal to the average value of `hours` by group, and `sd_hours` equal to the standard deviation (`sd()`) of `hours` by group. -->

<!-- ```{r qscores4-setup} -->
<!-- q_subset <- qscores %>% -->
<!--   select(department, hours) %>% -->
<!--   group_by(department) -->
<!-- ``` -->

<!-- ```{r qscores4, exercise = TRUE, exercise.lines = 4} -->

<!-- ``` -->

<!-- ```{r qscores4-hint-1, eval=FALSE} -->
<!-- # The n() function returns the number of rows in each group. -->
<!-- ``` -->

<!-- ```{r qscores4-hint-2, eval = FALSE} -->
<!-- q_subset <- q_subset %>% -->
<!--   summarize(num_classes = ..., mean_hours = ..., sd_hours = ...) -->
<!-- ``` -->

<!-- ### Exercise 5 -->

<!-- `arrange()` the data set by `num_classes` in `desc()`ending order. -->

<!-- ```{r qscores5-setup} -->
<!-- q_subset <- qscores %>% -->
<!--   select(department, hours) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) -->
<!-- ``` -->

<!-- ```{r qscores5, exercise = TRUE} -->

<!-- ``` -->

<!-- ### Exercise 6 -->

<!-- Use `slice()` to return the top 3 rows of the data set, i.e. the 3 largest departments at Harvard by number of classes. -->

<!-- ```{r qscores6-setup} -->
<!-- q_subset <- qscores %>% -->
<!--   select(department, hours) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>% -->
<!--   arrange(desc(num_classes)) -->
<!-- ``` -->

<!-- ```{r qscores6, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r qscores6-hint, eval=FALSE} -->
<!-- # Remember that a:b returns all of the numbers from a to b. For example, 1:10 returns every number between 1 and 10. -->
<!-- ``` -->

<!-- ### Exercise 7 -->

<!-- Group the data by `department` one more time (the data is no longer grouped since we removed some `department`s with our `slice()` statement). -->

<!-- ```{r qscores7-setup} -->
<!-- q_subset <- qscores %>% -->
<!--   select(department, hours) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>% -->
<!--   arrange(desc(num_classes)) %>% -->
<!--   slice(1:3) -->
<!-- ``` -->

<!-- ```{r qscores7, exercise = TRUE} -->

<!-- ``` -->

<!-- ### Exercise 8 -->

<!-- Using `summarize()`, create a new variable, `rnorm_values`. `rnorm_values` should be equal to the result of an `rnorm()` statement. The `rnorm()` statement should have `n` equal to `num_classes`, `mean` equal to `mean_hours`, and `sd` equal to `sd_hours` (in other words, we are generating `n` completely random numbers, but the numbers should have the same mean and standard deviation as the actual Harvard classes do). -->

<!-- ```{r qscores8-setup} -->
<!-- q_subset <- qscores %>% -->
<!--   select(department, hours) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>% -->
<!--   arrange(desc(num_classes)) %>% -->
<!--   slice(1:3) %>% -->
<!--   group_by(department) -->
<!-- ``` -->

<!-- ```{r qscores8, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r qscores8-hint, eval=FALSE} -->
<!-- qsubset <- q_subset %>% -->
<!--   summarize(rnorm_values = rnorm(...)) -->
<!-- ``` -->

<!-- ### Exercise 9 -->

<!-- Great work! Our next goal will be to create a new column with the homework values of the *actual* Harvard classes. To do so, start a new pipe at the very beginning of your code. Use the pipe to `filter()` qscores to the "ECON," "MATH," and "GOV" departments (which we have already discovered are the 3 largest departments in our data set). Call this `q_subset_2`.  -->

<!-- ```{r qscores9, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r qscores9-hint, eval=FALSE} -->
<!-- # Remember to use the %in% operator. -->
<!-- ``` -->

<!-- ### Exercise 10 -->

<!-- `arrange()` both `q_subset` and `q_subset_2` by `department`. (because `department` is a character variable, this will arrange them in alphabetical order). -->

<!-- ```{r qscores10-setup} -->
<!-- q_subset <- qscores %>% -->
<!--   select(department, hours) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>% -->
<!--   arrange(desc(num_classes)) %>% -->
<!--   slice(1:3) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(rnorm_values = rnorm(n = num_classes, mean = mean_hours, sd = sd_hours)) -->

<!-- q_subset_2 <- qscores %>% -->
<!--   filter(department %in% c("ECON", "MATH", "GOV")) -->
<!-- ``` -->

<!-- ```{r qscores10, exercise = TRUE} -->

<!-- ``` -->

<!-- ### Exercise 11 -->

<!-- `select()` only the `hours` variable from `q_subset_2`. -->
<!-- ```{r qscores11-setup} -->
<!-- q_subset_2 <- qscores %>% -->
<!--   filter(department %in% c("ECON", "MATH", "GOV")) %>% -->
<!--   arrange(department) -->

<!-- q_subset <- qscores %>% -->
<!--   select(department, hours) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>% -->
<!--   arrange(desc(num_classes)) %>% -->
<!--   slice(1:3) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(rnorm_values = rnorm(n = num_classes, mean = mean_hours, sd = sd_hours)) %>% -->
<!--   arrange(department) -->

<!-- ``` -->

<!-- ```{r qscores11, exercise = TRUE} -->

<!-- ``` -->

<!-- ### Exercise 12  -->

<!-- Finally, use `bind_cols()` to bind the columns in `q_subset_2` to the columns in `q_subset`. -->
<!-- Call this `q_bind`. -->

<!-- Notice how careful we were to `arrange()` both pipes by the same variable before we conducted our column bind. This is really important because the rows **must** be in the same order before you column bind. Otherwise, values will be bound to the wrong rows (for example, some `hours` from ECON classes might end up paired with some `rnorm_values` from MATH classes, which we certainly don't want). -->

<!-- ```{r qscores12-setup} -->
<!-- q_subset_2 <- qscores %>% -->
<!--   filter(department %in% c("ECON", "MATH", "GOV")) %>% -->
<!--   arrange(department) %>% -->
<!--   select(hours) -->

<!-- q_subset <- qscores %>% -->
<!--   select(department, hours) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>% -->
<!--   arrange(desc(num_classes)) %>% -->
<!--   slice(1:3) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(rnorm_values = rnorm(n = num_classes, mean = mean_hours, sd = sd_hours)) %>% -->
<!--   arrange(department) -->
<!-- ``` -->

<!-- ```{r qscores12, exercise = TRUE} -->

<!-- ``` -->

<!-- ### Exercise 13 -->

<!-- Before we make our `ggplot()`, use `pivot_longer()` to transform the `rnorm_values` and `hours` columns into two new columns: "type," equal to either `rnorm_values` or `hours`, and "value," equal to the value currently contained in one of those two columns. -->

<!-- ```{r qscores13-setup} -->
<!-- q_subset_2 <- qscores %>% -->
<!--   filter(department %in% c("ECON", "MATH", "GOV")) %>% -->
<!--   arrange(department) %>% -->
<!--   select(hours) -->

<!-- q_subset <- qscores %>% -->
<!--   select(department, hours) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>% -->
<!--   arrange(desc(num_classes)) %>% -->
<!--   slice(1:3) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(rnorm_values = rnorm(n = num_classes, mean = mean_hours, sd = sd_hours)) %>% -->
<!--   arrange(department) -->

<!-- q_bind <- bind_cols(q_subset, q_subset_2) -->
<!-- ``` -->

<!-- ```{r qscores13, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r qscores13-hint, eval = FALSE} -->

<!-- ``` -->

<!-- ### Exercise 14 -->

<!-- Use `ggplot()` to make a histogram that maps `value` to the x-axis. Give the histogram a `binwidth` of 2. Call this histogram `q_plot`.  -->
<!-- ```{r qscores14-setup} -->
<!-- q_subset_2 <- qscores %>% -->
<!--   filter(department %in% c("ECON", "MATH", "GOV")) %>% -->
<!--   arrange(department) %>% -->
<!--   select(hours) -->

<!-- q_subset <- qscores %>% -->
<!--   select(department, hours) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>% -->
<!--   arrange(desc(num_classes)) %>% -->
<!--   slice(1:3) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(rnorm_values = rnorm(n = num_classes, mean = mean_hours, sd = sd_hours)) %>% -->
<!--   arrange(department) -->

<!-- q_bind <- bind_cols(q_subset, q_subset_2) %>% -->
<!--   pivot_longer(cols = c(rnorm_values, hours), names_to = "type", values_to = "value") -->
<!-- ``` -->

<!-- ```{r qscores14, exercise = TRUE} -->

<!-- ``` -->

<!-- ### Exercise 15 -->

<!-- Use `facet_grid()` to facet our histogram into rows by `type` and columns by `department`. -->
<!-- ```{r qscores15-setup} -->
<!-- q_subset_2 <- qscores %>% -->
<!--   filter(department %in% c("ECON", "MATH", "GOV")) %>% -->
<!--   arrange(department) %>% -->
<!--   select(hours) -->

<!-- q_subset <- qscores %>% -->
<!--   select(department, hours) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>% -->
<!--   arrange(desc(num_classes)) %>% -->
<!--   slice(1:3) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(rnorm_values = rnorm(n = num_classes, mean = mean_hours, sd = sd_hours)) %>% -->
<!--   arrange(department) -->

<!-- q_bind <- bind_cols(q_subset, q_subset_2) %>% -->
<!--   pivot_longer(cols = c(rnorm_values, hours), names_to = "type", values_to = "value") -->

<!-- q_plot <- ggplot(data = q_bind, mapping = aes(x = value)) + -->
<!--     geom_histogram(binwidth = 2) -->
<!-- ``` -->

<!-- ```{r qscores15, exercise = TRUE, exercise.lines = 19} -->

<!-- ``` -->

<!-- ```{r qscores15-hint, eval=FALSE} -->
<!-- # Remember that when using facet_grid(), the variable to the left of the "~" is the variable that will be used to facet the graph into rows. -->
<!-- ``` -->

<!-- ### Exercise 16 -->

<!-- Awesome work! This graph gives the actual homework times for Harvard classes on the top row and an imitation on the bottom row by utilizing a normal distribution. The first thing to notice is that the MATH department has a significantly higher mean homework amount than the ECON and GOV departments (this is most easily seen on the bottom row of graphs). Furthermore, the graphs on the top tend to skew left compared to the normal distributions on the bottom, implying that professors are less willing to give substantially more homework than the typical class in that department. -->

<!-- To finish your plot, use `labs()` to give the graph a title and subtitle of your choice. -->

<!-- ```{r qscores16-setup} -->
<!-- q_subset_2 <- qscores %>% -->
<!--   filter(department %in% c("ECON", "MATH", "GOV")) %>% -->
<!--   arrange(department) %>% -->
<!--   select(hours) -->

<!-- q_subset <- qscores %>% -->
<!--   select(department, hours) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(num_classes = n(), mean_hours = mean(hours), sd_hours = sd(hours)) %>% -->
<!--   arrange(desc(num_classes)) %>% -->
<!--   slice(1:3) %>% -->
<!--   group_by(department) %>% -->
<!--   summarize(rnorm_values = rnorm(n = num_classes, mean = mean_hours, sd = sd_hours)) %>% -->
<!--   arrange(department) -->

<!-- q_bind <- bind_cols(q_subset, q_subset_2) %>% -->
<!--   pivot_longer(cols = c(rnorm_values, hours), names_to = "type", values_to = "value") -->

<!-- q_plot <- ggplot(data = q_bind, mapping = aes(x = value)) + -->
<!--     geom_histogram(binwidth = 2) + -->
<!--      facet_grid(type ~ department) -->
<!-- ``` -->

<!-- ```{r qscores16, exercise = TRUE, exercise.lines = 20} -->

<!-- ``` -->



## National Election Studies
###

<!-- DK: Lots of questions about .fun = first2. This either needs to be explained more slowly or left out. I am not even sure what it does, or what last2 does. -->

`nes`, short for "National Election Studies," contains the personal and political
information of almost 40,000 American voters, as well as whether or not they voted in that year's presidential election. The goal of this exercise is to replicate this plot:

```{r, echo=FALSE}
nes_plot <- nes %>%
  select(year, education, pres_appr, ideology, voted) %>%
  filter(education %in% c("Some Highschool", "Highschool", 
                          "Some College", "Adv. Degree")) %>%
  droplevels() %>%
  mutate(opinion = as.factor(if_else(
    condition = str_detect(pres_appr, "prove"),
    true = "has_opinion",
    false = "no_opinion"))) %>%
  drop_na() %>%
  group_by(year, voted, opinion, education) %>%
  summarize(count = n()) %>%
  pivot_wider(names_from = voted, values_from = count) %>%
  mutate(turnout = Yes / (Yes + No)) %>%
  drop_na() %>%
  ggplot(aes(x = year,
             y = turnout,
             color = fct_reorder2(education, year,
                                  turnout, .fun = first2),
             linetype = fct_reorder2(education, year, 
                                     turnout, .fun = first2))) +
  geom_line() +
  facet_wrap(~ opinion) +
  scale_color_brewer(palette = "Spectral", name = "education") +
  scale_linetype(name = "education") +
  labs(title = "Turnout and Opinions Over Time",
       subtitle = "People with opinions are more likely to vote",
       x = "Turnout Percentage",
       y = "Year")

nes_plot
```

Good luck!



### Exercise 1

Start by running `skim()` on `nes`. See if you can figure out the first and last
years in the data set. You may need to load the **skimr** package first.

```{r nes1, exercise = TRUE}

```


### Exercise 2

Use `levels()` and the `$` operator to explore the levels of the `education` variable.

```{r nes2, exercise = TRUE}

```

```{r nes2-hint}
# The factor that we'd like to investigate is nes$education.
```


### Exercise 3

Select the `year`, `education`, `pres_appr`, `ideology`, and `voted` columns from `nes`.

```{r nes3, exercise = TRUE}

```


### Exercise 4

Continue by filtering the tibble such that `education` is either "Some Highschool," "Highschool," "Some College," or "Adv. Degree."

```{r nes4, exercise = TRUE}

```

```{r nes4-hint}
# Remember to use the %in% operator along with the c() function.
```


### Exercise 5

After filtering a factor, always remember that the *levels* of the factor have not been removed. To fix this, add a call in the pipe that drops (i.e. permanently removes) all deleted levels.

```{r nes5, exercise = TRUE}

```

```{r nes5-hint}
# Use the droplevels() function.
```


### Exercise 6

The dplyr `if_else()` function can be used alongside `mutate()` and `as.factor()` to create a factor with two levels depending on whether a certain `condition` is met. Run the code below to see how we can use `if_else()` to separate the `nes` data set into 2 groups based on whether the value of `ideology` is positive.

```{r nes6, exercise = TRUE}
nes %>%
  select(year, education, pres_appr, ideology, voted) %>%
  filter(education %in% c("Some Highschool", "Highschool", 
                          "Some College", "Adv. Degree")) %>%
  droplevels() %>%
  mutate(pos_ideology = as.factor(if_else(condition = ideology > 0,
                                          true = "ideology_is_positive",
                                          false = "ideology_not_positive")))
```


### Exercise 7

Now, use `if_else()` and `mutate()` tto create a new variable, `opinion`. `opinion` should be a **factor** that equals "has_opinion" if that person either approves *or* disapproves of the president, but "no_opinion" otherwise. To do this, use the `if_else()` function with the condition being detection of the pattern "prove" in the string `pres_appr`. You can remove from your pipe the creation of `pos_ideology` since we won't be using that variable.

```{r nes7, exercise = TRUE, exercise.lines = 10}

```

```{r nes7-hint-1}
# Remember to use as.factor() before if_else().
```

```{r nes7-hint-2}
# The function we want to use for the condition is str_detect().
```

```{r nes7-hint-3, eval=FALSE}
nes %>%
  select(year, education, pres_appr, ideology, voted) %>%
  filter(education %in% c("Some Highschool", "Highschool", 
                          "Some College", "Adv. Degree")) %>%
  droplevels() %>%
  mutate(opinion = as.factor(if_else(condition = str_detect(...),
                                     true = ...,
                                     false = ...)))
```


### Exercise 8

Our goal for the next few exercises will be to calculate voter turnout based on education and whether or not the voter has an opinion of the president at that time.

To start, group the tibble by `year`, `voted`, `opinion`, and `education`. Then, use `summarize()` to make a new variable, `count`, that simply counts the number of people (i.e. rows) in each group. What goes wrong?

```{r nes8, exercise = TRUE, exercise.lines = 10}

```

```{r nes8-hint}
# Remember that the n() function counts the number of rows in each group.
```


### Exercise 9

If we look closely, many of our rows have a value of `NA` for either `voted` or `opinion`. Furthermore, `n()` doesn't have an `na.rm` argument. To remove the `NA`s, use tidyr's `drop_na()` to drop any rows with missing values for any variable before the call to `group_by()` and `summarize()`.

```{r nes9, exercise = TRUE, exercise.lines = 15}

```

```{r nes9-hint, eval = FALSE}
nes %>%
  select(year, education, pres_appr, ideology, voted) %>%
  filter(education %in% c("Some Highschool", "Highschool", 
                          "Some College", "Adv. Degree")) %>%
  droplevels() %>%
  mutate(opinion = as.factor(if_else(condition = str_detect(pres_appr, "prove"),
                                     true = "has_opinion",
                                     false = "no_opinion"))) %>%
  drop_na() %>%
  group_by(year, voted, opinion, education) %>%
  summarize(count = ...)
```


### Exercise 10

Our goal is to calculate voter turnout within each category, the number of people who voted divided by the total number of people. Therefore, we want `Yes` and `No` (currently in the `voted` column) to be their own columns with the values that are currently in the `count` column.

Use one of the `pivot_` functions to tidy our data in this way.

```{r nes10, exercise = TRUE, exercise.lines = 15}

```

```{r nes10-hint-1}
# Because we're making new columns from values, we want the pivot_wider()
# function.
```

```{r nes10-hint-2, eval = FALSE}
... %>%
  pivot_wider(names_from = ..., values_from = ...)
```


### Exercise 11

Great job! Now, to calculate turnout, use `mutate()` to create another variable, `turnout`, equal to the number of people who voted (the number of `Yes`) divided by the total number of people in each category. To make sure you are caught up, we provide the pipe as it should appear by this stage. You need to add a line to create `turnout`. But look at the data when you do! See the rows with are NA for turnout? That will mess up our graphics. So, use `drop_na()` again to remove them.

```{r nes11, exercise = TRUE, exercise.lines = 15}
nes %>%
  select(year, education, pres_appr, ideology, voted) %>%
  filter(education %in% c("Some Highschool", "Highschool", 
                          "Some College", "Adv. Degree")) %>%
  droplevels() %>%
  mutate(opinion = as.factor(if_else(condition = str_detect(pres_appr, "prove"),
                                     true = "has_opinion",
                                    false = "no_opinion"))) %>%
  drop_na() %>%
  group_by(year, voted, opinion, education) %>%
  summarize(count = n()) %>%
  pivot_wider(names_from = voted, values_from = count)
```

```{r nes11-hint}
# Remember that the total number of people in each group is (Yes + No).
```


### Exercise 12

Next, use `ggplot()` to make a line graph that maps `year` to the x-axis, `turnout` to the y-axis, and `education` to both the color and linetype aesthetics.

```{r nes12, exercise = TRUE}

```


### Exercise 13

Use `facet_wrap` to facet the graph by opinion.

```{r nes13, exercise = TRUE, exercise.lines = 15}

```


### Exercise 14

<!-- DK: This question ordering is weird and confusing. It is rarely a good idea to guide students to the "wrong" answer and then fix it in the next question. -->

This graph is starting to look pretty good, but the ordering of the legend is a bit confusing. Try using an `fct_` function to reorder the legend (both the color *and* linetype aesthetics) so that Adv. Degree is first, Some College is second, and so on. Something goes wrong with this first attempt, but we will fix it in the next exercise.

```{r nes14, exercise = TRUE, exercise.lines = 15}

```

```{r nes14-hint-1}
# Because this is a line graph, we want to use fct_reorder2().
```


### Exercise 15

Although 3 of the 4 `education` statuses are reordered successfully, Adv. Degree is left on the bottom because it doesn't appear in the second graph. To fix this problem, change the `.fun` argument of both `fct_reorder2()` calls to `first2` (the default is `last2`).

```{r nes15, exercise = TRUE, exercise.lines = 15}

```

```{r nes15-hint, eval = FALSE}
... %>%
  ggplot(aes(x = year, 
             y = turnout,
             color = fct_reorder2(education, year, 
                                  turnout, .fun = ...),
             linetype = fct_reorder2(education, year,
                                     turnout, .fun = ...))) +
  geom_line() +
  facet_wrap(~ opinion)
```


### Exercise 16

Our graph is looking good, but the very long legend title takes up a lot of space. To fix this problem (and to improve the colors of the graph), add a `scale_color_brewer()` function with the "Spectral" palette as well as a `scale_linetype` function. Use **both** scale functions to set the name of the legend to "education."

```{r nes16, exercise = TRUE, exercise.lines = 18}

```

```{r nes16-hint-1}
# The scale_color_brewer() function should take 2 arguments, but the
# scale_linetype() function should only take 1.
```


### Exercise 17

Amazing work! From this graph, we see that Americans with a higher level of education tend to vote more often. Furthermore, Americans with an opinion of the president generally have higher voter turnout than Americans without an opinion of the president. Finally, pretty much 100% of Americans with an advanced degree are able to form an opinion of the president (this is why there is no Advanced Degree line in the no_opinion graph: there are too few data points in the table).

To finish your plot, use `labs()` to give the graph a title and subtitle of your choosing, along with some axis labels. Here is our answer. It is OK if your answer looks somewhat different from ours. Something sure seems fishy about that perfectly flat red line on the right . . . Indeed, there are a couple of things about our plot which could be improved . . . Why not improve them?

```{r, echo=FALSE}
nes_plot
```

```{r nes17, exercise = TRUE, exercise.lines = 20}

```


## Airline Safety 
###

We will be focusing on the data set `airline_saftey` from the **fivethirtyeight** package. We will recreate this plot step-by-step.

```{r as-answer, echo=FALSE}
as_plot <- airline_safety %>%
  pivot_longer(c(incidents_85_99, incidents_00_14, fatal_accidents_00_14,
                 fatal_accidents_85_99, fatalities_00_14, fatalities_85_99),
               names_to = "type_date",
               values_to = "count") %>%
  separate(type_date, c("type", "date"), sep = "s_") %>%
  filter(date == "00_14", count > 0, type == "incident") %>%
  mutate(safety_value = avail_seat_km_per_week / count) %>%
  arrange(safety_value) %>%
  ggplot(aes(x = airline, y = safety_value)) +
    geom_col() +
    theme(axis.text = element_text(size = 5, angle = 90)) +
    labs(title = "Airline Safety",
         subtitle = "Airlines with more long-haul routes are safer",
         x = "Airline",
         y = "Distance per Incident")

as_plot
```


### Exercise 1

Start by taking a `glimpse` of `airline_safety`:

```{r as-1, exercise=TRUE}

```


### Exercise 2

Do you notice anything off about the `airline_saftey` data? It's untidy! Over the next few questions, we are going to fix this. Let's start by making the table "longer." Use `pivot_longer()` to pivot the columns `incidents_85_99`, `incidents_00_14`, `fatal_accidents_00_14`,`fatal_accidents_85_99`, `fatalities_00_14` and  `fatalities_85_99` into the two new columns `type_date` and `count`.

```{r as-2, exercise=TRUE}

```

```{r as-2-hint, eval=FALSE}
airline_safety %>%
  pivot_longer(c(..., ..., ...,..., ..., ...),
               names_to = "...", values_to = "...")
```


### Exercise 3

Nice! Do you see what our next step has to be? In our `type_date` column, we have data on both the type of incident and the date range in which it occurred. This should really be two columns. Let's use the `separate()` to separate `type_date` into the two columns `type` and `date`. Separate on the s_ characters by setting the `sep` argument inside of `separate()` to "s_".

```{r as-3, exercise=TRUE, exercise.lines = 10}

```

```{r as-3-hint, eval=FALSE}
... %>%
   separate(type_date, c("...", "..."), sep = "...")
```


### Exercise 4

Fantastic! Now that our data is tidy, we can get to work. Add a `filter()` to the pipe so that we narrow down our data set to data where date is "00_14", type is "incident", and count is greater than 0.

```{r as-4, exercise=TRUE, exercise.lines=10}

```


### Exercise 5

Nice! Now use `mutate()` to create the new variable `safety_value` and set it equal to `avail_seat_km_per_week` divided by `count`.

```{r as-5, exercise=TRUE, exercise.lines = 10}

```


### Exercise 6

Nice! Now arrange the data by `safety_value`.

```{r as-6, exercise=TRUE, exercise.lines = 10}

```


### Exercise 7

Great! Let's now use our wrangled data to create a bar plot using `geom_col()` with `airline` on the x axis and `safety_value` on the y axis. 

```{r as-7-setup}

```

```{r as-7, exercise=TRUE, exercise.lines=10}

```


### Exercise 8

Awesome! As you can see, the airline names on the y axis are crowded and basically impossible to read. Let's change this by using `theme()` and setting the x axis text `size` to 5 and `angle` to 90.

```{r as-8, exercise=TRUE, exercise.lines=15}

```

```{r as-8-hint, eval=FALSE}
... +
  theme(... = element_text(size = ..., angle = ...))
```


### Exercise 9

Great! Now add some labels to finish our plot off! Here is our version. As always, it is OK if yours looks different. Try to make it better!

```{r as-9-answer}
as_plot
```

```{r as-9, exercise=TRUE, exercise.lines=20}

```


<!-- ## Partisan Lean District -->
<!-- ### -->

<!-- We will be focusing on the data set `partisan_lean_district`, from the `fivethirtyeight` package. This data set includes the data which FiveThirtyEight uses for their political projections.   -->

<!-- ### Exercise 1 -->

<!-- Let's start by using the `skim()` function on `partisan_lean_district` -->

<!-- ```{r pld-1, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 2 -->

<!-- Great! Now `filter()` `partisan_lean_district` so that `pvi_party` equals R.  -->

<!-- ```{r pld-2, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 3 -->

<!-- Now select `pvi_amount` from `pld_subset`. -->

<!-- ```{r pld-3-setup} -->
<!-- pld_subset <- partisan_lean_district %>%  -->
<!--   filter(pvi_party == "R") -->
<!-- ``` -->

<!-- ```{r pld-3, exercise=TRUE} -->



<!-- ``` -->


<!-- ### Exercise 4 -->

<!-- Fantastic! Now use `summarize()` to calculate the mean and standard deviation of the `pvi_amount` column. -->
<!-- ```{r pld-4-setup} -->
<!-- pld_subset <- partisan_lean_district %>%  -->
<!--   filter(pvi_party == "R") %>% -->
<!--   select(pvi_amount) -->
<!-- ``` -->

<!-- ```{r pld-4, exercise=TRUE, eval=FALSE} -->

<!-- ``` -->

<!-- ```{r pld-4-hint, eval=FALSE} -->
<!-- pld_subset <- pld_subset %>% -->
<!--   summarize(mean = mean(...), std_dev = sd(...)) -->
<!-- ``` -->

<!-- ### Exercise 5 -->

<!-- For these next few questions, we will be using `rnorm`. Start by using `rnorm` to create a set of 241 observations with a mean of 23.2 and a standard deviation of 14.5.  -->

<!-- ```{r pld-5-setup} -->
<!-- pld_subset <- partisan_lean_district %>%  -->
<!--   filter(pvi_party == "R") %>% -->
<!--   select(pvi_amount) %>% -->
<!--   summarize(mean = mean(pvi_amount), std_dev = sd(pvi_amount)) -->
<!-- ``` -->

<!-- ```{r pld-5, exercise=TRUE, eval=FALSE} -->



<!-- ``` -->

<!-- ```{r pld-5-hint, eval=FALSE} -->
<!-- rnorm(n = ..., mean = ..., sd = ...) -->
<!-- ``` -->

<!-- ### Exercise 6 -->

<!-- Now use the `tibble()` function to turn our previous set of `rnorm()` observations into a data frame, and name this dataframe `pld_nd` -->

<!-- ```{r pld-6, exercise=TRUE, eval=FALSE, exercise.lines=10} -->


<!-- ``` -->

<!-- ```{r pld-6-hint, eval=FALSE} -->
<!-- ...  <- ...(value = rnorm(n = ..., mean = ..., sd = ...)) -->
<!-- ``` -->

<!-- ### Exercise 7 -->

<!-- Awesome! Now use our newly made data frame `pld_nd` to make a histogram.Call it `nd_plot`. -->

<!-- ```{r pld-7-setup} -->
<!-- pld_nd <- tibble(value = rnorm(n = 241, mean = 23.2, sd = 14.5)) -->
<!-- ``` -->

<!-- ```{r pld-7, exercise=TRUE, eval=FALSE} -->

<!-- ``` -->

<!-- ```{r pld-7-hint, eval=FALSE} -->
<!-- nd_plot <- ggplot(data = ..., aes(x = ...)) +  -->
<!--   geom_histogram() -->
<!-- ``` -->

<!-- ### Exercise 8 -->

<!-- Now, remake the plot and set the `fill` argument  to "red", the `alpha` argument to .2, and the `bins` argument set to 10. -->
<!-- ```{r pld-8-setup} -->
<!-- pld_nd <- tibble(value = rnorm(n = 241, mean = 23.2, sd = 14.5)) -->
<!-- ``` -->

<!-- ```{r pld-8, exercise=TRUE, eval=FALSE, exercise.lines=10} -->


<!-- ``` -->

<!-- ```{r pld-8-hint, eval=FALSE} -->
<!-- nd_plot <- ggplot(data = ..., aes(x = ...)) +  -->
<!--   geom_histogram(fill = ..., alpha = ..., bins = ...) -->
<!-- ``` -->

<!-- ### Exercise 9 -->

<!-- Nice! Let's now make a histogram with our filtered `pld_subset` data from earlier. We've taken the liberty of removing the final `summarize()` function from `pld_subset`. Put `pvi_amount` on the x axis, and call this plot `pld_plot`.  -->

<!-- ```{r pld-9-setup} -->
<!-- pld_subset <- partisan_lean_district %>%  -->
<!--   filter(pvi_party == "R") %>% -->
<!--   select(pvi_amount) -->
<!-- ``` -->

<!-- ```{r pld-9, exercise=TRUE} -->


<!-- ``` -->

<!-- ```{r pld-9-hint, eval=FALSE} -->
<!-- pld_plot <- ggplot(data = ..., mapping = aes(x = ...)) +  -->
<!--   geom_histogram() -->
<!-- ``` -->

<!-- ### Exercise 10 -->

<!-- Now set the `fill` argument to "blue", the `alpha` argument to 0.2,  and the `bins` argument to 10 -->
<!-- ```{r pld-10-setup} -->
<!-- pld_subset <- partisan_lean_district %>%  -->
<!--   filter(pvi_party == "R") %>% -->
<!--   arrange(pvi_amount) -->
<!-- ``` -->

<!-- ```{r pld-10, exercise=TRUE, eval=FALSE, exercise.lines=10} -->


<!-- ``` -->

<!-- ```{r pld-10-hint, eval=FALSE} -->
<!-- pld_plot <- ggplot(data = ..., mapping = aes(x = ...)) +  -->
<!--   geom_histogram(fill = ..., alpha = ..., bins = ....) -->
<!-- ``` -->



<!-- ## State Words -->

<!-- ### Exercise 1 -->

<!-- `state_words` is a data set from the `fivethirtyeight` package. The data set includes data on phrases repeated in speeches made by governors across the United States. Let's get started by using the `skim()` function on `state_words`. -->

<!-- ```{r sw-1, exercise=TRUE} -->


<!-- ``` -->

<!-- ### Exercise 2  -->

<!-- Nice! Now `filter()` `state_words` to only include rows where `category` is NOT equal to "NA". Then use the assignment operator `<-` to name this filtered data set `state_words_1` -->

<!-- ```{r sw-2, exercise=TRUE} -->


<!-- ``` -->

<!-- ### Exercise 3 -->

<!-- ```{r sw-3-setup} -->
<!-- state_words_1 <- state_words %>% -->
<!--   filter(category != "NA") -->
<!-- ``` -->
<!-- For the next few questions, we will be focusing on factors. Run the `levels()` function on the `category` factor of data set `state_words_1`. -->

<!-- ```{r sw-3, exercise=TRUE} -->


<!-- ``` -->

<!-- ```{r sw-3-hint, eval=FALSE} -->
<!-- # Consider using the $ operator. -->
<!-- ``` -->

<!-- ### Exercise 4 -->

<!-- Now use the `count()` function on `category` to create a frequency table. -->

<!-- ```{r sw-4, exercise=TRUE, exercise.setup = "sw-3-setup"} -->


<!-- ``` -->


<!-- ### Exercise 5 -->

<!-- Use `fct_reorder()` to reorder the factor levels in `state_words_1` by the mean of `d_speeches`. Then,  use the `levels()` function to take a look at what we have just done -->

<!-- ```{r sw-5, exercise=TRUE, exercise.setup = "sw-3-setup"} -->


<!-- ``` -->

<!-- ```{r sw-5-hint, eval=FALSE} -->
<!-- # Consider using the $ operator -->
<!-- ``` -->

<!-- ### Exercise 6 -->

<!-- Great! Now try using `fct_recode()` to recode the layer "economy/fiscal issues" of the factor `category` in `state_words_1` to be "economic/fiscal". Then use the `levels()` function on `state_words_1` to take a look at what we have just done -->

<!-- ```{r sw-6, exercise=TRUE, exercise.setup = "sw-3-setup"} -->


<!-- ``` -->

<!-- ### Exercise 7 -->

<!-- Let's now use our data to make a plot. (You won't need to use the previous two exercises for this plot). Use the data set `state_words_1` and `geom_col()` to make a bar graph with `category` on the x axis and `d_speeches` on the y axis. Call this plot `state_words_plot`. -->

<!-- ```{r sw-7, exercise=TRUE, eval=FALSE, exercise.setup = "sw-3-setup"} -->


<!-- ``` -->

<!-- ### Exercise 8 -->

<!-- Great! Remember the practice we did on questions 5 and 6? It should come in handy now! Use `fct_recode()` to recode the `category` factor on our x axis so that the layer "economy/fiscal issues" becomes "economic/fiscal". Call this plot `state_plot_2`.  -->


<!-- ```{r sw-8, exercise=TRUE, eval=FALSE, exercise.setup = "sw-3-setup"} -->


<!-- ``` -->

<!-- ```{r sw-8-hint, eval=FALSE} -->
<!-- state_plot_2 <- state_words_1 %>% -->
<!--   ggplot(aes(x = (...  %>% fct_recode( ... = ...)) , y = d_speeches)) + -->
<!--       geom_col() -->
<!-- ``` -->

<!-- ### Exercise 9 -->

<!-- Awesome! Let's add some labels and a title to finish off our plot! Add the labels "key phrase categories" and "speeches" to the x and y axes respectively, then add the title "Democratic Governor Talking Points" -->

<!-- ```{r sw-9-setup} -->
<!-- state_words_1 <- state_words %>% -->
<!--   filter(category != "NA")  -->
<!-- state_plot_2 <- state_words_1 %>% -->
<!--   ggplot(aes(x = (state_words_1$category  %>% fct_recode("economic/fiscal" = "economy/fiscal issues")) , y = d_speeches)) + -->
<!--       geom_col() -->
<!-- ``` -->

<!-- ```{r sw-9, exercise=TRUE} -->


<!-- ``` -->

<!-- ```{r sw-9-hint, eval=FALSE} -->
<!-- # use labs() -->
<!-- ``` -->

<!-- ## Mediacloud  -->

<!-- ### Exercise 1 -->

<!-- We are going to be looking at two different data sets, `mediacloud_hurricanes` and `mediacloud_states`  (both from the package `fivethirtyeight`). These two data sets include data on the number of sentences in online media which include mentions of key words related to hurricanes in 2017.  Let's start by using the skim function on both `mediacloud_hurricanes` and `mediacloud_states` to see what we are dealing with -->

<!-- ```{r mch-1, exercise=TRUE} -->

<!-- ``` -->


<!-- ### Exercise 2 -->

<!-- Great! Let's get to work. Use `left_join()` to join `mediacloud_hurricanes` and `mediacloud_states` by `date`.  -->

<!-- ```{r mch-2, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 3 -->

<!-- Nice! Try using `right_join()` to join `mediacloud_hurricanes` and `mediacloud_states` by `date`. How does this change the tibble? -->

<!-- ```{r mch-3, exercise=TRUE} -->

<!-- ``` -->


<!-- ### Exercise 4 -->

<!-- Cool! Now use the assignment operator `<-` to name our new left joined tibble `mediacloud_combined`.  -->

<!-- ```{r mch-4, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 5 -->

<!-- ```{r mch-5-setup} -->
<!-- mediacloud_combined <- left_join(mediacloud_hurricanes, mediacloud_states,"date") -->
<!-- ``` -->

<!-- Use `pivot_longer()` to pivot the columns `harvey`, `irma`, `maria`, `jose`, `texas`, `puerto_rico` and `florida` in `mediacloud_combined`. Put their names into a new column called "word" and their values into a new column called "mentions".  -->

<!-- ```{r mch-5, exercise=TRUE} -->

<!-- ``` -->

<!-- ```{r mch-5-hint, eval=FALSE} -->
<!-- mediacloud_combined %>% pivot_longer(..., names_to = "...", values_to = "...") -->
<!-- ``` -->

<!-- ### Exercise 6 -->

<!-- Awesome! Now, just like we did when we joined, use the assignment operator `<-` to name our new pivoted tibble `mediacloud_combined_tidy`.  -->

<!-- ```{r mch-6, exercise=TRUE, exercise.setup = "mch-5-setup"} -->

<!-- ``` -->


<!-- ### Exercise 7 -->

<!-- ```{r mch-7-setup} -->
<!-- mediacloud_combined <- left_join(mediacloud_hurricanes, mediacloud_states,"date") -->

<!-- mediacloud_combined_tidy <- mediacloud_combined %>% pivot_longer(c(`harvey`, `irma`, `maria`, `jose`, `texas`, `puerto_rico`, `florida`), names_to = "word", values_to = "mentions") -->
<!-- ``` -->

<!-- Nice! Now, let's use our wrangled data to make a plot! Use `geom_line()` to make a line graph with `date` on the x axis and `mentions` on the y axis. Call this plot `mediacloud_plot`.  -->

<!-- ```{r mch-7, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 8 -->

<!-- Hmmm, that plot isn't very useful. Copy your code from the last question, and try setting the `color` aesthetic to `word` -->

<!-- ```{r mch-8-setup} -->
<!-- mediacloud_combined <- left_join(mediacloud_hurricanes, mediacloud_states,"date") -->

<!-- mediacloud_combined_tidy <- mediacloud_combined %>% pivot_longer(c(`harvey`, `irma`, `maria`, `jose`, `texas`, `puerto_rico`, `florida`), names_to = "word", values_to = "mentions") -->
<!-- ``` -->


<!-- ```{r mch-8, exercise=TRUE} -->

<!-- ``` -->

<!-- ```{r mch-8-hint, eval=FALSE} -->
<!-- # Because color is an aesthetic, set it inside of aes() -->
<!-- ``` -->

<!-- ### Exercise 9 -->

<!-- Much better! Let's finish up our plot by adding a title of your choice with a `labs()` layer. -->

<!-- ```{r mch-9-setup} -->
<!-- mediacloud_combined <- left_join(mediacloud_hurricanes, mediacloud_states,"date") -->

<!-- mediacloud_combined_tidy <- mediacloud_combined %>% pivot_longer(c(`harvey`, `irma`, `maria`, `jose`, `texas`, `puerto_rico`, `florida`), names_to = "word", values_to = "mentions") -->

<!-- mediacloud_plot <- ggplot(data = mediacloud_combined_tidy,  -->
<!--                           aes(x = date, y = mentions, color = word)) + -->
<!--   geom_line() -->
<!-- ``` -->

<!-- ```{r mch-9, exercise=TRUE} -->

<!-- ``` -->

<!-- ## Unisex Names -->

<!-- ### Exercise 1 -->

<!-- We are going to be looking at `unisex_names`, a data set from the package `fivethirtyeight`, with data on the most popular unisex names. Let's start by taking a `glimpse()` of `unisex_names` -->

<!-- ```{r un-1, exercise=TRUE} -->


<!-- ``` -->

<!-- ### Exercise 2 -->

<!-- For the next few questions, we will be looking at  the variable `name` and practicing our string manipulation. Start by using the `str_subset()` function to create a vector containing only names that end in a "y" -->

<!-- ```{r un-2, exercise=TRUE} -->


<!-- ``` -->

<!-- ```{r un-2-hint-1, eval=FALSE} -->
<!-- # Consider using the regex $ -->
<!-- ``` -->

<!-- ```{r un-2-hint-2, eval=FALSE} -->
<!-- str_subset(..., pattern = "...") -->
<!-- ``` -->

<!-- ```{r un-2-hint-3, eval=FALSE} -->
<!-- str_subset(unisex_names$..., pattern = "...") -->
<!-- ``` -->

<!-- ### Exercise 3 -->

<!-- Now try doing the same thing but for names that end with "ie" -->

<!-- ```{r un-3, exercise=TRUE} -->


<!-- ``` -->

<!-- ### Exercise 4 -->

<!-- Now use `str_sub` to create a vector with only the first three letters of each string in `name` -->

<!-- ```{r un-4, exercise=TRUE, eval=FALSE, exercise.lines=6} -->


<!-- ``` -->

<!-- ### Exercise 5 -->

<!-- Use `mutate()` to create a column `first_letter` that uses `str_sub` to take the first letter of every name in the `name` column.  -->

<!-- ```{r un-5, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 6 -->

<!-- Awesome! Now use the `<-` assignment operator to save this to the new data set `unisex_names_1`. -->

<!-- ```{r un-6, exercise=TRUE} -->


<!-- ``` -->

<!-- ### Exercise 7 -->

<!-- ```{r un-7-setup} -->
<!-- unisex_names_1 <- unisex_names %>%  -->
<!--   mutate(first_letter = str_sub(unisex_names$name, 1,1)) -->
<!-- ``` -->

<!-- Now use `group_by()` and `summarize()` on `unisex_names_1` to create the variable `first_letter_avg`. Make `first_letter_avg` equal to the mean `total` of the names beginning with each `first_letter`[So the `first_letter_avg` for "C" should be the average number of living Americans (ie. the `total`) who have a specific name that starts with "C" which is included this data set. (This one is really confusing! Don't be afraid to look at the hint! Your resulting tibble should include two columns, one  being `first_letter_avg` and the other being `first_letter`.)] -->
<!-- ```{r un-7, exercise=TRUE} -->


<!-- ``` -->

<!-- ```{r un-7-hint-1, eval=FALSE} -->
<!-- unisex_names_1 %>%  -->
<!--   group_by(...) %>%  -->
<!--   summarize(... = mean(...)) -->
<!-- ``` -->

<!-- ### Exercise 8 -->

<!-- Awesome! Now use the `<-` assignment operator to save this to the new data set `unisex_names_2`. -->

<!-- ```{r un-8-setup} -->
<!-- unisex_names_1 <- unisex_names %>%  -->
<!--   mutate(first_letter = str_sub(unisex_names$name, 1,1)) -->
<!-- ``` -->

<!-- ```{r un-8, exercise=TRUE, eval=FALSE} -->


<!-- ``` -->

<!-- ```{r un-8-hint, eval=FALSE} -->
<!-- ... <- unisex_names_1 %>% -->
<!--   group_by(...) %>%  -->
<!--   summarize(mean = mean(...)) -->
<!-- ``` -->

<!-- ### Exercise 9 -->

<!-- ```{r un-9-setup} -->
<!-- unisex_names_1 <- unisex_names %>%  -->
<!--   mutate(first_letter = str_sub(unisex_names$name, 1,1)) -->

<!-- unisex_names_2 <- unisex_names_1 %>% -->
<!--   group_by(first_letter) %>%  -->
<!--   summarize(mean = mean(total)) -->
<!-- ``` -->

<!-- Let's use our data to make a plot. Use `unisex_names_2` and `geom_col()` to make a bar graph with `first_letter` on the x axis and `first_letter_avg` on the y axis -->

<!-- ```{r un-9, exercise=TRUE} -->

<!-- ``` -->

<!-- ```{r un-9-hint, eval=FALSE} -->

<!-- ``` -->

<!-- ## Bad Drivers -->

<!-- ### Exercise 1 -->

<!-- Let's do some data wrangling with the `bad_drivers` tibble from the `fivethirtyeight` package! First `skim()` the `bad_drivers` dataset. -->

<!-- ```{r bd1, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 2 -->

<!-- Use `select()` to remove `num_drivers`, `insurance_premiums`, and `losses` from the tibble. Call this `bd_subset`.  -->

<!-- ```{r bd-2, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 3 -->

<!-- You may have noticed by looking at the tibble, Use `pivot_longer` on all of the columns except for the `state` column, and then set `names_to` `type` and `values_to` `percent`. -->


<!-- ```{r bd3-setup} -->
<!-- bd_subset <- bad_drivers %>% select(-c(num_drivers, insurance_premiums, losses)) -->
<!-- ``` -->


<!-- ```{r bd3, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 4 -->

<!-- Now, we have a nice and tidy tibble. But we're not quite done yet. The first five characters in every value of our `type` column are `perc_`, which does nothing but clutter up our tibble. -->

<!-- Let's use `mutate()` and `str_remove()` to get rid of it. -->

<!-- ```{r bd4-setup} -->
<!-- bd_subset <- bad_drivers %>% select(-c(num_drivers, insurance_premiums, losses)) %>% -->
<!--   pivot_longer(cols = -state, names_to = "type", values_to = "percent") -->
<!-- ``` -->

<!-- ```{r bd4, exercise=TRUE} -->

<!-- ``` -->

<!-- ```{r bd4-hint, eval=FALSE} -->
<!-- # `mutate` our `type` variable such that we `str_remove` the `pattern` = "perc_" -->
<!-- ``` -->



<!-- ### Exercise 5 -->

<!-- Now, we have a neat and tidy tibble, that's much easier to manipulate. Let's say that now we want to find the 5 states that have the highest `percent` of fatal accidents linked to `alcohol`. `filter()` to choose only our rows where `type` == "alcohol". -->

<!-- ```{r bd5-setup} -->
<!-- bd_subset <- bad_drivers %>% select(-c(num_drivers, insurance_premiums, losses)) %>% -->
<!--   pivot_longer(cols = -state, names_to = "type", values_to = "percent") %>% -->
<!--   mutate(type = str_remove(type, pattern = "perc_")) -->
<!-- ``` -->

<!-- ```{r bd-5, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 6 -->

<!-- Use `arrange(desc())` to sort our values in descending order of `percent`. -->

<!-- ```{r bd6-setup} -->
<!-- bd_subset <- bad_drivers %>% select(-c(num_drivers, insurance_premiums, losses)) %>% -->
<!--   pivot_longer(cols = -state, names_to = "type", values_to = "percent") %>% -->
<!--   mutate(type = str_remove(type, pattern = "perc_")) %>% -->
<!--   filter(type == "alcohol") -->
<!-- ``` -->

<!-- ```{r bd6, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 7 -->

<!-- Use the `head()` function to select the first `5` rows of our tibble. -->

<!-- ```{r bd7-setup} -->
<!-- bd_subset <- bad_drivers %>% select(-c(num_drivers, insurance_premiums, losses)) %>% -->
<!--   pivot_longer(cols = -state, names_to = "type", values_to = "percent") %>% -->
<!--   mutate(type = str_remove(type, pattern = "perc_")) %>% -->
<!--   filter(type == "alcohol") %>% -->
<!--   arrange(desc(percent)) -->
<!-- ``` -->

<!-- ```{r bd7, exercise = TRUE} -->

<!-- ``` -->

<!-- ### Exercise 8 -->

<!-- Make a barplot using `ggplot()` and `geom_col()`. We'll map `x` to `state`, and y to `percent`. Call it `bd_plot`. -->

<!-- ```{r bd8-setup} -->
<!-- bd_subset <- bad_drivers %>% select(-c(num_drivers, insurance_premiums, losses)) %>% -->
<!--   pivot_longer(cols = -state, names_to = "type", values_to = "percent") %>% -->
<!--   mutate(type = str_remove(type, pattern = "perc_")) %>% -->
<!--   filter(type == "alcohol") %>% -->
<!--   arrange(desc(percent)) %>% -->
<!--   head(5) -->
<!-- ``` -->

<!-- ```{r bd8, exercise = TRUE} -->

<!-- ``` -->

<!-- ### Exercise 9 -->

<!-- Title `bd_plot` "The Five States with the Highest Percent of Fatal Accidents from Alcohol", our x-axis "State", and our y-axis "Percent of Fatal Automobile Accidents from Alcohol". -->
<!-- ```{r bd9-setup} -->
<!-- bd_subset <- bad_drivers %>% select(-c(num_drivers, insurance_premiums, losses)) %>% -->
<!--   pivot_longer(cols = -state, names_to = "type", values_to = "percent") %>% -->
<!--   mutate(type = str_remove(type, pattern = "perc_")) %>% -->
<!--   filter(type == "alcohol") %>% -->
<!--   arrange(desc(percent)) %>% -->
<!--   head(5) -->

<!-- bd_plot <- ggplot(data = bd_subset, aes(x = state, y = percent), fill = state) +  -->
<!--   geom_col() +  -->
<!--   labs(title = "The Five States with the Highest Percent of Fatal Accidents from Alcohol", -->
<!--        x = "State", -->
<!--        y = "Percent of Fatal Automobile Accidents") -->
<!-- ``` -->

<!-- ```{r bd9, exercise = TRUE} -->

<!-- ``` -->

<!-- ## US births -->

<!-- ### Exercise 1 -->

<!-- Let's do some data wrangling with the `US_births_1994_2003` tibble from the `fivthirtyeight` package. Use  `glimpse()` to get a good look at the tibble. -->

<!-- ```{r usb1, exercise = TRUE} -->

<!-- ``` -->

<!-- ### Exercise 2 -->

<!-- Call on `US_births_1994_2003`, and `%>%` it into a `filter()` function. We will filter by `year` == "2000".  Call this `USB_2000` -->

<!-- ```{r usb2, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 3 -->

<!-- Run our filtered tibble into a `select()` function. Right now, our data is not tidy, and all the information in `month`, `date_of_month`, `year`, and `day_of_week` can be extrapolated from just `date`. We will remove the other columns to simplify our tibble. Let's select only the `date` and `births` columns. -->

<!-- ```{r usb3-setup} -->
<!-- USB_2000 <- US_births_1994_2003 %>% -->
<!--   filter(year == 2000)  -->
<!-- ``` -->

<!-- ```{r usb3, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 4 -->

<!-- Use `mutate(... = yday(...))` to create a new column for our tibble, `day_number` which will record the number of the day of year for each value in `date`. -->

<!-- ```{r usb4-setup} -->
<!-- USB_2000 <- US_births_1994_2003 %>% -->
<!--   filter(year == 2000) %>% -->
<!--   select(date, births) -->
<!-- ``` -->

<!-- ```{r usb4, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 5 -->

<!-- Use `ggplot` and `geom_line()`, map x to `day_number` and y to `births`. Call this plot `births_plot`. -->

<!-- ```{r usb5-setup} -->
<!-- USB_2000 <- US_births_1994_2003 %>% -->
<!--   filter(year == 2000) %>% -->
<!--   select(date, births) %>% -->
<!--   mutate(day_number = yday(date)) -->
<!-- ``` -->

<!-- ```{r usb5, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 6 -->

<!-- This plot is interesting, but it makes it clear that the relationship between number of births and day of the week is much greater than the relationship between number of births and the time of year.  -->

<!-- So let's go back to the drawing board. Why don't we instead try to find the average number of births for each week, and then create a line plot from the resulting averages. -->

<!-- Use `mutate(... = week(...))` to make a new column, `week_number` of `USB_2000`, that will record the number of the week of every value in `date`. -->

<!-- ```{r usb6-setup} -->
<!-- USB_2000 <- US_births_1994_2003 %>% -->
<!--   filter(year == 2000) %>% -->
<!--   select(date, births) %>% mutate(day_number = yday(date)) %>% -->
<!--   mutate(week_number = week(date)) -->
<!-- ``` -->

<!-- ```{r usb6, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 7 -->

<!-- Use `group_by()` to group our tibble's rows by `week_number`. -->

<!-- ```{r usb7-setup} -->
<!-- USB_2000 <- US_births_1994_2003 %>% -->
<!--   filter(year == 2000) %>% -->
<!--   select(date, births) %>% mutate(day_number = yday(date)) %>% -->
<!--   mutate(week_number = week(date)) %>% -->
<!--   group_by(week_number) -->
<!-- ``` -->

<!-- ```{r usb7, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 8 -->

<!-- Now, use `summarize()` and the `mean()` function to make yet another variable, `avg_week_births`, that number of `births` across each week.  -->

<!-- ```{r usb8-setup} -->
<!-- USB_2000 <- US_births_1994_2003 %>% -->
<!--   filter(year == 2000) %>% -->
<!--   select(date, births) %>% mutate(day_number = yday(date)) %>% -->
<!--   mutate(week_number = week(date)) %>% -->
<!--   group_by(week_number) -->
<!-- ``` -->

<!-- ```{r usb8, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 9 -->

<!-- Now, we're ready to make a plot again with `ggplot()` and `geom_line()`. Map x to `week_number`, and y to `avg_week_births`. Call this `births_plot_2`.  -->
<!-- ```{r usb9-setup} -->
<!-- USB_2000 <- US_births_1994_2003 %>% -->
<!--   filter(year == 2000) %>% -->
<!--   select(date, births) %>% mutate(day_number = yday(date)) %>% -->
<!--   mutate(week_number = week(date)) %>% -->
<!--   group_by(week_number) %>% -->
<!--   summarize(avg_week_births = mean(births)) -->
<!-- ``` -->

<!-- ```{r usb9, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 10 -->

<!-- Now, we can finish off our plot by adding a `labs()` layer. Title our plot "Average Daily Births by Week of the Year 2000", our x-axis "Week of the Year", and our y-axis "Average Daily Births". -->
<!-- ```{r usb10-setup} -->
<!-- USB_2000 <- US_births_1994_2003 %>% -->
<!--   filter(year == 2000) %>% -->
<!--   select(date, births) %>% mutate(day_number = yday(date)) %>% -->
<!--   mutate(week_number = week(date)) %>% -->
<!--   group_by(week_number) %>% -->
<!--   summarize(avg_week_births = mean(births)) -->

<!-- births_plot_2 <- ggplot(data = USB_2000, mapping = aes(x = week_number, y = avg_week_births)) + -->
<!--   geom_line() -->
<!-- ``` -->

<!-- ```{r usb10, exercise=TRUE} -->

<!-- ``` -->

<!-- ## Daily Show Guests -->

<!-- ### Exercise 1 -->

<!-- Let's do some data wrangling with the `daily_show_guests` tibble from the `fivethirtyeight` tibble. Run `daily_show_guests` to get a run-down on the data in the tibble. Unlike many of the other tibbles we've worked with in this chapter, this one only contains 5 columns, so we don't need to use `glimpse()` or `skim()` to get a grasp of all the data. -->

<!-- Let's say that our goal with this exercise is to create a list of a few fake names that are somewhat similar, but still different to the names of popular celebrities for parody purposes. -->

<!-- ```{r dsg1, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 2 -->

<!-- If you notice, some of our columns have needlessly long and confusing names.  -->
<!-- We can tackle this with `rename()`. Let's rename our columns such that `occupation` = `google_knowledge_occupation`, and `guest` = `raw_guest_list`. Although this won't change anything about our data, it will make the tibble easier for us to work with. Call this tibble `ds_guests`. -->

<!-- ```{r dsg2, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 3 -->

<!-- Now, let's get wrangling. Let's `filter()` `ds_guests` our data to only contain guests whose `occupation` is "actor". -->

<!-- ```{r dsg3-setup} -->
<!-- ds_guests <- daily_show_guests %>% -->
<!--   rename("occupation" = google_knowledge_occupation, -->
<!--          "guest" = raw_guest_list) -->
<!-- ``` -->

<!-- ```{r dsg3, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 4 -->

<!-- Now, suppose you wanted to pick out all of the actors whose name starts with "C". Use the `$` operator and `str_subset()` on the `guest` column of `ds_guests`. Call this atomic vector `C_guests`.   -->
<!-- ```{r dsg4-setup} -->
<!-- ds_guests <- daily_show_guests %>% -->
<!--   rename("occupation" = google_knowledge_occupation, -->
<!--          "guest" = raw_guest_list) %>% -->
<!--   filter(occupation == "actor") -->
<!-- ``` -->

<!-- ```{r dsg4, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r dsg4-hint, eval=FALSE} -->
<!-- # Consider using the regex ^  -->
<!-- ``` -->


<!-- ### Exercise 5 -->

<!-- But as I'm sure you've noticed, we have quite a few duplicate names. Colin Firth alone shows up 7 times! -->

<!-- We can remove these duplicates using the `unique()` function. Try it on `C_guests`! -->


<!-- ```{r dsg5-setup} -->
<!-- ds_guests <- daily_show_guests %>% -->
<!--   rename("occupation" = google_knowledge_occupation, -->
<!--          "guest" = raw_guest_list) %>% -->
<!--   filter(occupation == "actor")  -->

<!-- C_guests <- str_subset(ds_guests$guest, pattern = "^C") -->
<!-- ``` -->

<!-- ```{r dsg5, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 6 -->

<!-- Much better. Now, let's go back to `str_subset()` to select only the names that contain an `r`, followed by any number of random characters before an `n`. -->

<!-- ```{r dsg6-setup} -->
<!-- ds_guests <- daily_show_guests %>% -->
<!--   rename("occupation" = google_knowledge_occupation, -->
<!--          "guest" = raw_guest_list) %>% -->
<!--   filter(occupation == "actor")  -->

<!-- C_guests <- str_subset(ds_guests$guest, pattern = "^C") %>% -->
<!--   unique() -->
<!-- ``` -->

<!-- ```{r dsg6, exercise=TRUE} -->

<!-- ``` -->

<!-- ```{r dsg6-hint, eval=FALSE} -->
<!-- # Consider using the regex `.*` -->
<!-- ``` -->

<!-- ### Exercise 7 -->

<!-- Now, let's use `str_replace_all()` to change every capital letter in each name to the letter "P". This doesn't really accomplish anything productive, but I think it's kind of funny. -->

<!-- ```{r dsg7-setup} -->
<!-- ds_guests <- daily_show_guests %>% -->
<!--   rename("occupation" = google_knowledge_occupation, -->
<!--          "guest" = raw_guest_list) %>% -->
<!--   filter(occupation == "actor")  -->

<!-- C_guests <- str_subset(ds_guests$guest, pattern = "^C") %>% -->
<!--   unique() %>% -->
<!--   str_subset(., pattern = "r.*n") -->
<!-- ``` -->

<!-- ```{r dsg7, exercise=TRUE} -->

<!-- ``` -->

<!-- ```{r dsg7-hint, eval=FALSE} -->
<!-- # Consider using the regex "[A-Z]"  -->
<!-- ``` -->

<!-- ### Exercise 8 -->

<!-- Let's use `str_remove()` to get remove the first "i" in each name.  -->

<!-- Note that if we wanted to remove every "i", we could use `str_remove_all()` -->

<!-- ```{r dsg8-setup} -->
<!-- ds_guests <- daily_show_guests %>% -->
<!--   rename("occupation" = google_knowledge_occupation, -->
<!--          "guest" = raw_guest_list) %>% -->
<!--   filter(occupation == "actor")  -->

<!-- C_guests <- str_subset(ds_guests$guest, pattern = "^C") %>% -->
<!--   unique() %>% -->
<!--   str_subset(., pattern = "r.*n") %>% -->
<!--   str_replace_all(., pattern = "[A-Z]", replacement = "P") -->
<!-- ``` -->

<!-- ```{r dsg8, exercise=TRUE} -->

<!-- ``` -->

<!-- ## Fandango -->

<!-- ### Exercise 1 -->

<!-- Let's do some data wrangling with the `fandango` tibble from the `fivethirtyeight` package. Run `glimpse()` on `fandango`, so we can get a grasp on all of its data. -->

<!-- ```{r fan1, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 2 -->

<!-- Let's begin by using `select()` to pick out the `film`, `fandango_stars`, `metacritic_norm_round`, `imdb_norm_round`, and `rt_norm_round` columns. Call this new tibble `fan_subset` -->

<!-- ```{r fan2, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 3 -->

<!-- Now let's use `rename()` to tidy up our variable names. Make `fandango` = `fandango_stars`, `metacritic` = `metacritic_norm_round`, `imdb` = `imdb_norm_round` and `rotten_tomatoes` = `rt_norm_round`. -->
<!-- ```{r fan3-setup} -->
<!-- fan_subset <- fandango %>% -->
<!--   select(film, fandango_stars, metacritic_norm_round, imdb_norm_round, rt_norm_round) -->
<!-- ``` -->

<!-- ```{r fan3, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 5 -->

<!-- Let's use `mutate()` to make a new column, `avg`, that's equal to the `mean()` score across all four of our columns (except for the `film` column).  -->
<!-- ```{r fan4-setup} -->
<!-- fan_subset <- fandango %>% -->
<!--   select(film, fandango_stars, metacritic_norm_round, imdb_norm_round, rt_norm_round) %>% -->
<!--   rename("fandango" = fandango_stars, -->
<!--          "metacritic" = metacritic_norm_round, -->
<!--          "imdb" = imdb_norm_round, -->
<!--          "rotten_tomatoes" = rt_norm_round) -->
<!-- ``` -->

<!-- ```{r fan4, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 5 -->

<!-- But let's say we want to make `avg` rounded to the nearest 0.5, like every other column.  -->

<!-- This is actually a bit tricky, because the `round()` function in R will only round to the nearest decimal place. However, we can get around it using some clever arithmetic. Once again, we're using `mutate()` because we're making a vector from a vector. -->

<!-- Change `avg` to be equal to `round()` of `avg * 2`, to `0` decimal places (using the `digits` argument) and then dividing the result by 2. -->

<!-- ```{r fan5-setup} -->
<!-- fan_subset <- fandango %>% -->
<!--   select(film, fandango_stars, metacritic_norm_round, imdb_norm_round, rt_norm_round) %>% -->
<!--   rename("fandango" = fandango_stars, -->
<!--          "metacritic" = metacritic_norm_round, -->
<!--          "imdb" = imdb_norm_round, -->
<!--          "rotten_tomatoes" = rt_norm_round) %>% -->
<!--   mutate(avg = (fandango + metacritic + imdb + rotten_tomatoes) / 4) -->
<!-- ``` -->

<!-- ```{r fan5, exercise=TRUE} -->

<!-- ``` -->

<!-- ```{r fan5-hint, eval=FALSE} -->
<!-- ... <- fan_subset %>% -->
<!--   mutate(avg = round(x = ..., digits = ...)/2) -->
<!-- ``` -->

<!-- ### Exercise 6 -->

<!-- Now that we have all of our columns, we can make our data tidy using the `pivot_longer()` function. We're going to be using every column except for `film`, putting our variable names into a new column called `critic_website`, and our values into a new column called `score`. -->

<!-- ```{r fan6-setup} -->
<!-- fan_subset <- fandango %>% -->
<!--   select(film, fandango_stars, metacritic_norm_round, imdb_norm_round, rt_norm_round) %>% -->
<!--   rename("fandango" = fandango_stars, -->
<!--          "metacritic" = metacritic_norm_round, -->
<!--          "imdb" = imdb_norm_round, -->
<!--          "rotten_tomatoes" = rt_norm_round) %>% -->
<!--   mutate(avg = (fandango + metacritic + imdb + rotten_tomatoes) / 4) %>% -->
<!--   mutate(avg = round(x = avg, digits = 2) / 2) -->
<!-- ``` -->

<!-- ```{r fan6, exercise=TRUE} -->

<!-- ``` -->

<!-- ```{r fan6-hint, eval=FALSE} -->
<!-- ... %>% pivot_longer(cols = -film, names_to = "...", values_to = "...") -->
<!-- ``` -->

<!-- ### Exercise 7 -->

<!-- Let's use our tidy data to make a boxplot with `ggplot()` `geom_boxplot()` Map x to `critic_website` and y to `score`. Call this plot `fan_plot`.  -->

<!-- ```{r fan7-setup} -->
<!-- fan_subset <- fandango %>% -->
<!--   select(film, fandango_stars, metacritic_norm_round, imdb_norm_round, rt_norm_round) %>% -->
<!--   rename("fandango" = fandango_stars, -->
<!--          "metacritic" = metacritic_norm_round, -->
<!--          "imdb" = imdb_norm_round, -->
<!--          "rotten_tomatoes" = rt_norm_round) %>% -->
<!--   mutate(avg = (fandango + metacritic + imdb + rotten_tomatoes) / 4) %>% -->
<!--   mutate(avg = round(x = avg, digits = 0) / 2) %>%  -->
<!--   pivot_longer(cols = -film, names_to = "critic_website", values_to = "score") -->
<!-- ``` -->

<!-- ```{r fan7, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 8 -->

<!-- Let's use `theme_classic()` to change the theme of our plot. -->

<!-- ```{r fan8-setup} -->
<!-- fan_subset <- fandango %>% -->
<!--   select(film, fandango_stars, metacritic_norm_round, imdb_norm_round, rt_norm_round) %>% -->
<!--   rename("fandango" = fandango_stars, -->
<!--          "metacritic" = metacritic_norm_round, -->
<!--          "imdb" = imdb_norm_round, -->
<!--          "rotten_tomatoes" = rt_norm_round) %>% -->
<!--   mutate(avg = (fandango + metacritic + imdb + rotten_tomatoes) / 4) %>% -->
<!--   mutate(avg = round(x = avg, digits = 0) / 2) %>%  -->
<!--   pivot_longer(cols = -film, names_to = "critic_website", values_to = "score") -->

<!-- fan_plot <- ggplot(data = fan_subset,  -->
<!--                    mapping = aes(x = critic_website, y = score)) +  -->
<!--   geom_boxplot() -->
<!-- ``` -->

<!-- ```{r fan8, exercise=TRUE} -->

<!-- ``` -->

<!-- ### Exercise 9 -->

<!-- Good. Let's also add some labels with `labs()`. Title the plot "Average Movie Scores from Different Critic Websites", our x-axis "Critic Website", and our y-axis "Score (Out of 5)" -->

<!-- ```{r fan9-setup} -->
<!-- fan_subset <- fandango %>% -->
<!--   select(film, fandango_stars, metacritic_norm_round, imdb_norm_round, rt_norm_round) %>% -->
<!--   rename("fandango" = fandango_stars, -->
<!--          "metacritic" = metacritic_norm_round, -->
<!--          "imdb" = imdb_norm_round, -->
<!--          "rotten_tomatoes" = rt_norm_round) %>% -->
<!--   mutate(avg = (fandango + metacritic + imdb + rotten_tomatoes) / 4) %>% -->
<!--   mutate(avg = round(x = avg, digits = 0) / 2) %>%  -->
<!--   pivot_longer(cols = -film, names_to = "critic_website", values_to = "score") -->

<!-- fan_plot <- ggplot(data = fan_subset,  -->
<!--                    mapping = aes(x = critic_website, y = score)) +  -->
<!--   geom_boxplot() + -->
<!--   theme_classic() -->
<!-- ``` -->

<!-- ```{r fan9, exercise=TRUE} -->

<!-- ``` -->

## Submit

```{r context="setup"}
submission_ui
```

```{r context="server"}
submission_server()
```

