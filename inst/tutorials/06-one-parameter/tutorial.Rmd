---
title: "One Parameter"
tutorial:
  id: "06-one-parameter"
output:
  learnr::tutorial:
      progressive: true
      allow_skip: true
runtime: shiny_prerendered
description: "Chapter 6 tutorial"
---

<!-- Things to Fix: -->

<!-- 0) Find all the DK comments and address them -->
<!-- 1) Do not use map2. It is too much for this tutorial. Just fix one of the numbers and only allow the other one to change. Save map2 for the problem set. -->
<!-- 2) Each section finishes with a nice plot. The student is show the plot in the last step and told to, approximately, replicate it. Of course, this will just involve adding a couple of items to whatever was the version in the second to last question. -->
<!-- MF: The middle, especially when we get into map2, is far beyond what I think a student will know after reading the chapter once. If we want mapping in the tutorial, I can ammend it to be a simpler explanation. On the other hand, if I have my chapter open, I'm supposed to be able to do the questions easily, right? In which case, mapping should be taken out here or added to my chapter meaningfully. -->


```{r setup, include=FALSE}
library(tidyverse)
library(PPBDS.data)
library(learnr)
library(shiny)
library(skimr)
library(infer)
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
options(tutorial.storage="local")  

# Key Data

set.seed(9)
urn <- tibble(color = c(rep("red", 925), rep("white", 575))) %>%
  slice_sample(prop = 1)
```

## Name

```{r name, echo=FALSE}
question_text(
  "Student Name:",
  answer(NULL, correct = TRUE),
  incorrect = "Ok",
  try_again_button = "Modify your answer",
  allow_retry = TRUE
)
```

## The "virtual shovel"
###

We have created a virtual urn with some unknown amount of red beads and white beads. Our goal will eventually be to estimate the total number of red beads in the urn.

To view the urn, simply type `urn` in the window below and hit "Run Code".

```{r shovel1, exercise = TRUE}

```

###

It appears that there are 1,500 beads in the urn (i.e. 1,500 rows in our tibble). Is this really the case? Run `nrow()` on `urn` to confirm the number of beads in the urn.

```{r shovel2, exercise = TRUE}

```

###

To simulate the process of real-world sampling, where we generally won't know exactly how many items are in our population, pipe `urn` into `rep_sample_n()` from the **infer** package, with a shovel `size` of 20 (i.e. the sample should have 20 observations). This simulates drawing a sample of size 20 from our urn one time.

```{r shovel3, exercise = TRUE}

```

```{r shovel3-hint, eval = FALSE}
urn %>%
  rep_sample_n(...)
```

###

Continuing your pipe, use `mutate()` to create two new variables: `is_red` should be a logical equal to the result of asking if `color` is "red," and `is_white` should be identical but replaced with the `color` "white." Remember to copy and paste your code from the previous exercise.

```{r shovel4, exercise = TRUE}

```

```{r shovel4-hint}
# is_red should be equal to (color == "red").
```

###

Next, use `summarize()` to create two more variables. `num_red` should be equal to the `sum()` of the `is_red` column, and `num_white` should be equal to the `sum()` of the `is_white` column. Are you reading *The Primer* before --- or at least as the same time as --- doing this Tutorial? If not, this won't make much sense.

```{r shovel5, exercise = TRUE}

```

```{r shovel5-hint, eval = FALSE}
summarize(num_red = ..., num_white = ...)
```

###

Call `mutate()` to create the variable `prop_red`, the proportion of the sampled beads that are red. Set `prop_red` equal to the number of red beads divided by the sum of the number of red beads and white beads.

```{r shovel6, exercise = TRUE}

```

```{r shovel6-hint}
# The proportion of red beads is num_red / (num_red + num_white).
```

###

Finally, use `mutate()` to create the `estimated_red` variable, our estimate of the number of red beads in the urn. `estimated_red` should be equal to `prop_red` multiplied by 1,500, the total number of beads in the urn.

```{r shovel7, exercise = TRUE}

```

###

Nice work! Running the code below gives us a way to virtually sample our urn in 20-bead increments. Notice that running the code multiple times gives us different estimates for the number of red beads in the urn. Each time we re-run the code, `rep_sample_n()` grabs a different sample from the urn.

Our next step will be to use our "virtual shovel" 50 times and create a distribution of our results. Start by setting the `reps` argument of `rep_sample_n()` to 50. Up until now, the default value of `reps` has been 1. By setting `reps` to 50, we are telling our machine to sample 20 beads from the urn fifty times. Set the `replace` argument to `TRUE`. This is equivalent to sampling with replacement, which is what we want. You will also need to set the `.groups` argument in summarize to something like "drop" to get rid of the error message.

```{r shovel8, exercise = TRUE, exercise.lines = 7}
urn %>%
  rep_sample_n(size = 20) %>%
  mutate(is_red = (color == "red"), is_white = (color == "white")) %>%
  summarize(num_red = sum(is_red), 
            num_white = sum(is_white)) %>%
  mutate(prop_red = num_red / (num_red + num_white)) %>%
  mutate(estimated_red = prop_red * 1500)
```

###

Use `ggplot()` and `geom_histogram()` to create a histogram that maps our 50 values of `estimated_red` to the x-axis.

```{r shovel9, exercise = TRUE}

```

###

Let's make our graph easier to read by setting the histogram's `binwidth` to 75 and `color` to "white."

```{r shovel10, exercise = TRUE}

```

###

We can use the `breaks` argument of a `scale_` function, alongside the `seq()` function, to reset the location of the tick marks on either axis. Run the code below to see how we can reset the tick marks on the y-axis to the even numbers from 0 to 20.

```{r shovel11, exercise = TRUE, exercise.lines = 10}
urn %>%
  rep_sample_n(size = 20, reps = 50, replace = TRUE) %>%
  mutate(is_red = (color == "red"), 
         is_white = (color == "white"), 
         .groups = "drop") %>%
  summarize(num_red = sum(is_red), 
            num_white = sum(is_white)) %>%
  mutate(prop_red = num_red / (num_red + num_white)) %>%
  mutate(estimated_red = prop_red * 1500) %>%
  ggplot(mapping = aes(x = estimated_red)) +
    geom_histogram(binwidth = 75, color = "white") +
    scale_y_continuous(breaks = seq(from = 0, to = 20, by = 2))
```

###

Use `scale_x_continuous()` to reset the tick marks on the x-axis to the multiples of 100 between 0 and 1,500. Copy and paste the code from the previous exercise to visualize the adjustment that we made to the y-axis and apply it to this prompt.

```{r shovel12, exercise = TRUE}

```

```{r shovel12-hint}
# The "by" argument of your seq() function should be 100.
```

###

Great job! By running the code below a few times, we see that the number of red beads in the urn is probably somewhere between 700 and 1,100. We'll learn more about how to refine our estimate in later sections.

To finish this graph, use `labs()` to rename the x-axis label to "Estimated number of red beads". Set `reps` equal to 500. Additionally, give the graph a suitable title of your choice. Here is our version. Yours should look something like this, but does not need to be exactly the same.

```{r shovel-final}
urn %>%
  rep_sample_n(size = 20, reps = 50, replace = TRUE) %>%
  mutate(is_red = (color == "red"), 
         is_white = (color == "white"), 
         .groups = "drop") %>%
  summarize(num_red = sum(is_red), 
            num_white = sum(is_white)) %>%
  mutate(prop_red = num_red / (num_red + num_white)) %>%
  mutate(estimated_red = prop_red * 1500) %>%
  ggplot(mapping = aes(x = estimated_red)) +
    geom_histogram(binwidth = 75, color = "white") +
    scale_y_continuous(breaks = seq(from = 0, to = 20, by = 2)) +
    scale_x_continuous(breaks = seq(from = 0, to = 1500, by = 100)) +
  labs(title = "Range of Estimates Using Shovel of Size 20",
       x = "Estimated number of red beads")
```


```{r shovel13, exercise = TRUE, exercise.lines = 20}

```


## Multiple sample sizes
###

In this section, we're going to analyze the effect of increased sample size and increased number of samples by using the `map()` family of functions from the **purrr** package, which is part of the Tidyverse.

Let's start by practicing how to create our own functions. Run the code below to see how we can define a function that rounds a number's square root to the nearest integer.

```{r map1, exercise = TRUE, exercise.lines = 6}
rounded_sqrt <- function(x) {
  round(sqrt(x))
}
rounded_sqrt(6)
rounded_sqrt(7)
```

###

In the code chunk below, write a function `mean_squares()` that calculates the `mean()` of the squares of two numbers, `x` and `y`. Then, use your function to calcuate the mean of $6^2$ and $14^2$. Remember that `mean()` takes in a vector as its input. Your answer when you run `mean_squares(6, 14)` should be 116.

```{r map2, exercise = TRUE}

```

```{r map2-hint-1}
# The vector that you pass into the mean() function should be c(x^2, y^2).
```

```{r map2-hint-2, eval = FALSE}
mean_squares <- function(...) {
  mean(...)
}
mean_squares(...)
```

###

<!-- DK: I don't like the way that this code just assumes that urn is floating around in the global namespace. Didn't we fix this in the chapter? You should be forced to pass in the urn. -->

<!-- MF: Clarification- do you mean you want students to see the creation of the object 'urn' first? Or am I misunderstanding? -->

The code chunk below contains the code that we made in the previous exercise to sample 20 beads 50 times from our urn. To generalize this code for any sample `size` and number of `reps`, wrap the code below in a new function, `sample_urn`. `sample_urn` should have 2 parameters: `size` (equal to the `size` of the `rep_sample_n()`) and `reps` (equal to the number of `reps` in the `rep_sample_n()`).

```{r map3, exercise = TRUE, exercise.lines = 7}
urn %>%
  rep_sample_n(size = 20, reps = 50, replace = TRUE) %>%
  mutate(is_red = (color == "red"), 
         is_white = (color == "white")) %>%
  summarize(num_red = sum(is_red), 
            num_white = sum(is_white), 
            .groups = "drop") %>%
  mutate(prop_red = num_red / (num_red + num_white)) %>%
  mutate(estimated_red = prop_red * 1500)
```

```{r map3-hint, eval = FALSE}
sample_urn <- function(...) {
  urn %>%
    rep_sample_n(size = ..., reps = ..., replace = TRUE) %>%
    mutate(is_red = (color == "red"), is_white = (color == "white")) %>%
    summarize(num_red = sum(is_red), 
              num_white = sum(is_white), 
              .groups = "drop") %>%
    mutate(prop_red = num_red / (num_red + num_white)) %>%
    mutate(estimated_red = prop_red * 1500)
}
```

###

Nice work! Next, below the `sample_urn()` function, call `tibble()` to create a new tibble with 2 columns. `sample_size` should be equal to the vector `(20, 20, 100, 100)`, and `num_reps` should be equal to the vector `(50, 100, 50, 100)`. Remember to copy and paste your code from the previous exercise so you have the `sample_urn()` function in your code above the tibble.

```{r map4, exercise = TRUE}

```

```{r map4-hint, eval = FALSE}
tibble(sample_size = ..., 
       num_reps = ...)
```

###

Pipe your tibble into a `mutate()` statement to create the new variable `sample_results`. Although it will produce an error, set `sample_results` equal to the result of a `sample_urn()` called with `size` equal to `sample_size` and `reps` equal to `num_reps`. Try to figure out why you received this error.

```{r map5, exercise = TRUE}

```

###

<!-- DK: This is too hard! Why use map2? -->

<!-- MF: I agree. Is axeing it entirely fine or do you want some mapping to be in this tutorial? -->

Because we want to apply `sample_urn()` to every row, we need to use a **purrr** `map_*()` function. First, copy and paste your code from the previous exercise. Then, set `sample_results` equal to a `map()` statement with three arguments passed to it: `sample_size`, `num_reps`, and the `sample_urn()` call from the previous exercise. Again, see if you can figure out why you receive an error.

```{r map6, exercise = TRUE}

```

```{r map6-hint, eval = FALSE}
tibble(sample_size = c(20, 20, 100, 100), 
       num_reps = c(50, 100, 50, 100)) %>%
  mutate(sample_results = map(..., ..., ...))
```

###

We're on the right track, but we have to remember the two rules of calling expressions inside `map()` (in this case, our `sample_urn()` expression). First, begin your expression with the `~` character. Second, replace all instances of `sample_size` with `.x` and all instances of `num_reps` with `.y`. After running the function, you should not receive an error, but see if you can figure out why something is still wrong.

```{r map7, exercise = TRUE}

```

```{r map7-hint, eval = FALSE}
mutate(sample_results = map(sample_size, num_reps, ...))
```

###

We finally don't get an error when we run our code! Unfortunately, the `sample_results` column is all `NULL`. This is because `map()` only works with one variable, so it can't handle our `sample_urn()` expression that uses *two* variables, `sample_size` and `num_reps`. To fix this final problem, all you need to do is replace `map()` with `map2()`. Then, continue on to the next exercise.

```{r map8, exercise = TRUE}

```

###

Fantastic work! The `sample_results` column of our tibble now contains 4 lists, each of which contains a series of samples with varying sample size and number of reps. Unfortunately, `ggplot()` can't actually graph lists, so we need someway to convert our list column into a normal tibble.

Luckily, tidyr gives us the `unnest()` function, which unnests a list column (also known as nested lists) into a tibble. Pipe the tibble into `unnest()` with the `unnest()` parameter `cols` (the columns we want to unnest) equal to `sample_results`.

```{r map9, exercise = TRUE, exercise.lines = 12}
sample_urn <- function(size, reps) {
  urn %>%
    rep_sample_n(size = size, reps = reps, replace = TRUE) %>%
    mutate(is_red = (color == "red"), is_white = (color == "white")) %>%
    summarize(num_red = sum(is_red), 
              num_white = sum(is_white), 
              .groups = "drop") %>%
    mutate(prop_red = num_red / (num_red + num_white)) %>%
    mutate(estimated_red = prop_red * 1500)
}

tibble(sample_size = c(20, 20, 100, 100), 
       num_reps = c(50, 100, 50, 100)) %>%
  mutate(sample_results = map2(sample_size, num_reps, 
                               ~ sample_urn(size = .x, reps = .y)))
```

```{r map9-hint, eval = FALSE}
tibble(sample_size = c(20, 20, 100, 100), num_reps = c(50, 100, 50, 100)) %>%
  mutate(sample_results = map2(sample_size, num_reps, 
                               ~ sample_urn(size = .x, reps = .y))) %>%
  unnest(...)
```

###

Pipe the `unnest()`ed tibble into `ggplot()` to make a histogram that maps `estimated_red` to the x-axis.

```{r map10, exercise = TRUE}

```

###

As in the previous section, improve the aesthetics of the histogram by setting `binwidth` to 75 and `color` to "white."

```{r map11, exercise = TRUE}

```

###

The histogram is starting to look good, but we still don't see how sample size and number of samples impact our distribution. Use `facet_grid()` to facet the histogram into *rows* by `num_reps` and into *columns* by `sample_size`.

```{r map12, exercise = TRUE}

```

```{r map12-hint}
# Always put the variable that you're faceting into rows by before the variable that you're faceting into columns by.
```

###

It's really hard to tell what exactly the difference is between the two rows and the two columns. Set the `labeller` parameter of `facet_grid()` to "label_both" to clarify the graph's facets.

```{r map13, exercise = TRUE}

```

###

<!-- DK: Show the final graph and then ask the student to replicate it. -->

Great job! This graph tells us a lot about the impact of sample size and number of samples on a distribution. As we go from the graphs on the left to the graphs on the right (an increase in sample size), the distributions become much more concentrated around the mean. Also, as we go from the graphs on the top to the graphs on the bottom (an increase in number of samples), the graphs become substantially more similar to a smooth curve---in other words, there is less variance in the height of the bars.

Finish your graph by using `labs()` to insert a title of your choice.

```{r map14, exercise = TRUE, exercise.lines = 16}
sample_urn <- function(size, reps) {
  urn %>%
    rep_sample_n(size = size, reps = reps, replace = TRUE) %>%
    mutate(is_red = (color == "red"), is_white = (color == "white")) %>%
    summarize(num_red = sum(is_red), 
              num_white = sum(is_white), 
              .groups = "drop") %>%
    mutate(prop_red = num_red / (num_red + num_white)) %>%
    mutate(estimated_red = prop_red * 1500)
}

tibble(sample_size = c(20, 20, 100, 100), 
       num_reps = c(50, 100, 50, 100)) %>%
  mutate(sample_results = map2(sample_size, num_reps, 
                               ~ sample_urn(size = .x, reps = .y))) %>%
  unnest(cols = sample_results) %>%
  ggplot(mapping = aes(x = estimated_red)) +
    geom_histogram(binwidth = 75, color = "white") +
    facet_grid(num_reps ~ sample_size, labeller = label_both)
```


## Standard deviation
###

In the last section, we figured out that an increase in sample size leads to greater precision in the sampling distribution. But how can we mathematically measure this increase in precision? The standard deviation of a set of values gives us a mathetmatical framework for measuring precision---reread chapter 2 in the textbook if you need clarification.

In the code cunk below, run `sd()` (the function that returns standard deviation) on the vector `c(1, 2, 3, 4, 5)`.

```{r sd1, exercise = TRUE}

```

```{r sd1-hint}
# Remember that the vector above is equal to 1:5.
```

###

This time, calculate the standard deviation of the vector `c(143, 144, 145, 146, 147)`. See if you can predict what the result will be before you run the code.

```{r sd2, exercise = TRUE}

```

```{r sd2-hint}
# Similarly to the previous exercise, the vector above is equal to 143:147.
```

###

Calculate the standard deviation of the vector `c(2, 3, 4)` and compare the result to the results from the previous two exercises.

```{r sd3, exercise = TRUE}

```

###

Calculate the standard deviation of the vector `c(7, 7, 7, 7, 7)`. See if you can predict the result before you run the code.

```{r sd4, exercise = TRUE}

```

```{r sd4-hint}
# You can use the rep() function to make this easier (though you don't have to).
```

###

Finally, calculate the standard deviation of `c(1, 1, 1, 5, 5)` and compare the result to the result of the first exercise.

```{r sd5, exercise = TRUE}

```

```{r sd5-hint, eval = FALSE}
sd(c(...))
```

###

Since we'll need it for the next exercise, let's recap the `seq()` function. Run the code below to see how we can return all multiples of 3 between 21 and 48.

```{r sd5_2, exercise = TRUE}
seq(from = 21, to = 48, by = 3)
```

###

Now that have an intuitive understanding of how standard deviation works, let's apply it to our urn sampling from the previous section. The code below contains our final work from the previous section, excluding our `ggplot()`.

Let's start by adjusting our `sample_size` vector (the first line of code in the bottom pipe). For now, set `sample_size` equal to the result of a `seq()` statement that has every even number `from` 6 `to` 40. Don't worry if you get an error (you should).

<!-- DK: Again, map2 is too hard for this tutorial. -->

```{r sd6, exercise = TRUE,  exercise.lines = 13}
sample_urn <- function(size, reps) {
  urn %>%
    rep_sample_n(size = size, reps = reps, replace = TRUE) %>%
    mutate(is_red = (color == "red"), 
           is_white = (color == "white")) %>%
    summarize(num_red = sum(is_red), 
              num_white = sum(is_white), 
              .groups = "drop") %>%
    mutate(prop_red = num_red / (num_red + num_white)) %>%
    mutate(estimated_red = prop_red * 1500)
}

tibble(sample_size = c(20, 20, 100, 100), 
       num_reps = c(50, 100, 50, 100)) %>%
  mutate(sample_results = map2(sample_size, num_reps, 
                               ~ sample_urn(size = .x, reps = .y))) %>%
  unnest(cols = sample_results)
```

```{r sd6-hint, eval = FALSE}
tibble(sample_size = seq(from = ..., to = ..., by = ...), 
       num_reps = c(50, 100, 50, 100))
```

###

To refine our `sample_size` vector, use the `c()` function to set `sample_size` equal to the first five integers (`1:5`) combined with the `seq()` statement from the previous exercise. Remember to copy and paste your code from the previous exercise, and again, ignore the error for the time being.

```{r sd7, exercise = TRUE, message = FALSE}

```

```{r sd7-hint, eval = FALSE}
tibble(sample_size = c(..., seq(...)), 
       num_reps = c(50, 100, 50, 100))
```

###

Since we're going to need it in the next exercise, let's quickly recap the `rep()` function. Run the code below to see how we can make a vector with the number 14 repeated 30 times.

```{r sd8, exercise = TRUE}
rep(14, 30)
```

###

The reason why we get an error is because our `num_reps` vector is not the same length is our `sample_size` vector. To fix the problem, use `rep()` to set `num_reps` equal to the number 50 repeated 23 times.

```{r sd9, exercise = TRUE, exercise.lines = 13, eval=FALSE}
sample_urn <- function(size, reps) {
  urn %>%
    rep_sample_n(size = size, reps = reps, replace = TRUE) %>%
    mutate(is_red = (color == "red"), 
           is_white = (color == "white")) %>%
    summarize(num_red = sum(is_red), 
              num_white = sum(is_white), 
              .groups = "drop") %>%
    mutate(prop_red = num_red / (num_red + num_white)) %>%
    mutate(estimated_red = prop_red * 1500)
}

tibble(sample_size = c(1:5, seq(from = 6, to = 40, by = 2)), 
       num_reps = c(50, 100, 50, 100)) %>%
  mutate(sample_results = map2(sample_size, num_reps, 
                               ~ sample_urn(size = .x, reps = .y))) %>%
  unnest(cols = sample_results)
```

```{r sd9-hint, eval = FALSE}
tibble(sample_size = c(1:5, seq(from = 6, to = 40, by = 2)), 
       num_reps = ...)
```

###

Nice work! Let's continue our pipe after the `unnest()` call by using `group_by()` to group the pipe by `sample_size`.

```{r sd10, exercise = TRUE, message = FALSE}

```

###

Continue the pipe by using `summarize()` to create the variable `sd_red`. `sd_red` should be equal to the standard deviation of the `estimated_red` variable in each group.

```{r sd11, exercise = TRUE, message = FALSE}

```

###

Pipe the tibble into `ggplot()` to create a scatterplot that maps `sample_size` to the x-axis and `sd_red` to the y-axis.

```{r sd12, exercise = TRUE, message = FALSE}

```

###

Finally, use `labs()` to set the `x`-axis label to "Sample size," the `y`-axis label to "Standard deviation of the number of red beads," and the graph's `title` to "How sample size affects the standard deviation of the sample."

```{r sd13, exercise = TRUE, message = FALSE}

```

###

Great job! From this graph, we can see the general trend that standard deviation decreases as sample size increases. However, the natural variation makes it a bit difficult to analyze the shape of the curve.

To make the relationship between standard deviation and sample size much easier to see, finish your graph by changing the number of `reps` per sample from 50 to 500 (you'll have to change the number inside the `rep()` function).

<!-- DK: Again, end with a graphic and require that the student reproduce it. -->

```{r sd14, exercise = TRUE,  exercise.lines = 20}
sample_urn <- function(size, reps) {
  urn %>%
    rep_sample_n(size = size, reps = reps, replace = TRUE) %>%
    mutate(is_red = (color == "red"), 
           is_white = (color == "white")) %>%
    summarize(num_red = sum(is_red), 
              num_white = sum(is_white), 
              .groups = "drop") %>%
    mutate(prop_red = num_red / (num_red + num_white)) %>%
    mutate(estimated_red = prop_red * 1500)
}

tibble(sample_size = c(1:5, seq(from = 6, to = 40, by = 2)), 
       num_reps = rep(50, 23)) %>%
  mutate(sample_results = map2(sample_size, num_reps, 
                               ~ sample_urn(size = .x, reps = .y))) %>%
  unnest(cols = sample_results) %>%
  group_by(sample_size) %>%
  summarize(sd_red = sd(estimated_red)) %>%
  ggplot(mapping = aes(x = sample_size, y = sd_red)) +
    geom_point() +
    labs(x = "Sample size",
         y = "Standard deviation of the number of red beads",
         title = "How sample size affects the standard deviation of the sample")
```

```{r sd14-hint, eval = FALSE}
tibble(sample_size = c(1:5, seq(from = 6, to = 40, by = 2)), 
       num_reps = rep(...))
```


## Posterior distribution from sample

###

Finally, let's return to our question from the original section: how can we predict the number of beads in the urn based on the results of a sample? In the first section, we discovered that the number of red beads in the urn was probably somewhere between 700 and 1,100, but we could not come up with a better estimate. In this section, we will both improve our estimate and better simulate real-world sampling by estimating the number of beads in the urn from the result of a single sample.

Suppose that in a single 45-bead sample from our urn, 28 of the 45 beads are red. Let's use this information to predict the number of beads in the urn.

We're going to start by analyzing a single model: 800 of the 1,500 beads being red. Using `tibble()`, create a tibble with a single column, `color`. `color` should be equal to the combination (`c()`) of "red" 800 times and "white" 700 times. Feel free to return to the previous section if you need a reminder of how to use `rep()`.

```{r posterior1, exercise = TRUE}

```

```{r posterior1-hint-1}
# Remember that rep("some_word", number_of_times) creates a vector with the word repeated that number of times.
```

```{r posterior1-hint-2, eval = FALSE}
tibble(color = c(rep(...), rep(...)))
```

###

Next, let's take some samples from our table using `rep_sample_n()`. The first parameter of your `rep_sample_n()` statement should be equal to the tibble that you made in the previous exercise (remember to copy and paste!). In addition, set the `size` of `rep_sample_n()` to 45, the `reps` to 1,000 (any reasonably large number works here), and `replace` to "TRUE."

```{r posterior2, exercise = TRUE}

```

```{r posterior2-hint, eval = FALSE}
tibble(...) %>% 
  rep_sample_n(size = ..., reps = ..., replace = ...)
```

###

Pipe what you have into `group_by()` to group the tibble by the `replicate` variable.

```{r posterior3, exercise = TRUE}

```

###

Using `summarize()`, create the variable `red_in_sample`, which should be equal to the `sum()` of the number of rows in each group with `color` equal to "red."

```{r posterior4, exercise = TRUE}

```

```{r posterior4-hint}
# The argument of your sum() function should be (color == "red").
```

###

We now have code that makes 1,000 random samples from our 800-red-bead urn, but we want to generalize it to urns with other amounts of red beads. To do so, wrap the code above in a function named `sample_given_urn` that has one parameter, `red_in_urn`. Replace the 800 in the first `rep()` statement with `red_in_urn` and the 700 in the second `rep()` statement with `red_in_urn` subtracted from 1,500. 

```{r posterior5, exercise = TRUE}

```

```{r posterior5-hint, eval = FALSE}
sample_given_urn <- function(...) {
  tibble(color = c(rep("red", ...), rep("white", ...))) %>% 
    rep_sample_n(size = 45, reps = 1000, replace = TRUE) %>%
    group_by(replicate) %>%
    summarize(red_in_sample = sum(color == "red"), .groups = "drop")
}
```

###

Great job! We now have a function that will randomly generate 1,000 45-bead samples from an urn with any number of red beads.

To get a sense of how our function works, call `sample_given_urn()` below the function definition to calculate 1,000 random samples from an urn with 650 red beads.

```{r posterior6, exercise = TRUE, exercise.lines = 7}
sample_given_urn <- function(red_in_urn){
  tibble(color = c(rep("red", red_in_urn), 
                   rep("white", 1500 - red_in_urn))) %>% 
    rep_sample_n(size = 45, reps = 1000, replace = TRUE) %>%
    group_by(replicate) %>%
    summarize(red_in_sample = sum(color == "red"), .groups = "drop")
}
```

###

Now, below the function definition, call `tibble()` to create a new tibble with one column, `nums`, equal to the vector containing every multiple of 25 `from` 650 `to` 1,150 (feel free to return to the previous section if you need a quick refresher on `seq()`).

One quick note---if this were a serious sampling problem, we would create a tibble with every integer between 0 and 1,500 (representing all possible combinations of red and white beads in our urn). However, since that code would take a couple minutes to run, we'll keep it to multiples of 25 in this tutorial.

```{r posterior7, exercise = TRUE, exercise.lines = 7}
sample_given_urn <- function(red_in_urn){
  tibble(color = c(rep("red", red_in_urn), 
                   rep("white", 1500 - red_in_urn))) %>% 
    rep_sample_n(size = 45, reps = 1000, replace = TRUE) %>%
    group_by(replicate) %>%
    summarize(red_in_sample = sum(color == "red"), .groups = "drop")
}
```

```{r posterior7-hint, eval = FALSE}
tibble(nums = seq(...))
```

###

Pipe your tibble into a `mutate()` statement to create the new variable `sample_results`. For now, `sample_results` should be equal to the result of a `map()` statement whose first parameter is `nums` and whose second parameter is `sample_given_urn(nums)`. As usual, don't worry about the error for the time being.

```{r posterior8, exercise = TRUE}

```

###

To fix the error from our `map()` statement, remember the two rules of using `map()`: replace `nums` with `.x` in `sample_given_urn()`, and precede `sample_given_urn()` with the `~` symbol.

```{r posterior9, exercise = TRUE}

```

###

Nice job! Unfortunately, we are now left with a list column. Just as we did in the previous sections, pipe the tibble into `unnest()` to convert the list column into a standard tibble. Set the `cols` argument of `unnest()` equal to `sample_results`.

```{r posterior10, exercise = TRUE}

```

###

Continuing your pipe, group the tibble by `nums`.

```{r posterior11, exercise = TRUE, exercise.lines = 11}
sample_given_urn <- function(red_in_urn){
  tibble(color = c(rep("red", red_in_urn), 
                   rep("white", 1500 - red_in_urn))) %>% 
    rep_sample_n(size = 45, reps = 1000, replace = TRUE) %>%
    group_by(replicate) %>%
    summarize(red_in_sample = sum(color == "red"), .groups = "drop")
}

tibble(nums = seq(from = 650, to = 1150, by = 25)) %>%
  mutate(sample_results = map(nums, ~ sample_given_urn(.x))) %>%
  unnest(cols = sample_results)
```

###

Use `summarize()` to create the variable `num_samples`. `num_samples` should be equal to the `sum()` of the number of rows in each group with `red_in_sample` equal to 28.

```{r posterior12, exercise = TRUE}

```

###

Pipe the tibble into `ggplot()` to create a bar graph that maps `nums` to the x-axis and `num_samples` to the y-axis.

```{r posterior13, exercise = TRUE}

```

```{r posterior13-hint}
# Remember to use geom_col().
```

###

Normalize the distribution by changing the y-axis mapping from `num_samples` to `num_samples` divided by the `sum()` of all `num_samples`. In addition, because the probabilities are so small, multiply `num_samples` by 100 before you divide by the `sum()` so we get percents instead of decimal probabilities.

```{r posterior14, exercise = TRUE}

```

```{r posterior14-hint, eval = FALSE}
ggplot(mapping = aes(x = nums, y = ... * ... / sum(...)))
```

###

Call `scale_x_continuous()` to change the tick marks on the x-axis by setting the `breaks` parameter to the multiples of 50 between 650 and 1,150 (use the `seq()` function like we did in the `tibble()` statement at the beginning of the pipe).

```{r posterior15, exercise = TRUE}

```

```{r posterior15-hint, eval = FALSE}
scale_x_continuous(breaks = seq(...))
```

###

Finally, use `labs()` to set the graph's `title` to "Posterior Probability Distribution of Red Beads in Urn," `subtitle` to "Based on a 45-bead sample with 28 red beads," `x`-axis label to "Number of red beads," and `y`-axis label to "Probability (percent)."

```{r posterior16, exercise = TRUE}

```

###

Fantastic job! From this graph, we can see that the most likely outcome for the number of red beads in the urn is between 900 and 975. Notably, though, there is a *ton* of variance in the outcome: the probability that the number of red beads is between 900 and 950 is only about 30%. The major lesson here is that a single small sample is not very predictive---you need either many samples or a very large sample size to be confident in your estimate.

To finish off this tutorial, you probably want to know how many red beads are actually in the urn. Below the `ggplot()`, pipe `urn` into a `count()` statement that takes `color` as its argument.

```{r posterior17, exercise = TRUE, exercise.lines = 20}
sample_given_urn <- function(red_in_urn){
  tibble(color = c(rep("red", red_in_urn), 
                   rep("white", 1500 - red_in_urn))) %>% 
    rep_sample_n(size = 45, reps = 1000, replace = TRUE) %>%
    group_by(replicate) %>%
    summarize(red_in_sample = sum(color == "red"), .groups = "drop")
}

tibble(nums = seq(from = 650, to = 1150, by = 25)) %>%
  mutate(sample_results = map(nums, ~ sample_given_urn(.x))) %>%
  unnest(cols = sample_results) %>%
  group_by(nums) %>%
  summarize(num_samples = sum(red_in_sample == 28), .groups = "drop") %>%
  ggplot(mapping = aes(x = nums, y = 100 * num_samples / sum(num_samples))) +
    geom_col() +
    scale_x_continuous(breaks = seq(from = 650, to = 1150, by = 50)) +
    labs(title = "Posterior Probability Distribution of Red Beads in Urn",
         subtitle = "Based on a 45-bead sample with 28 red beads",
         x = "Number of red beads",
         y = "Probability (percent)")
```

```{r posterior17-hint, eval = FALSE}
urn %>%
  count(...)
```



## Submit

```{r context="setup"}
submission_ui
```

```{r context="server"}
submission_server()
```
